<!-- generated by the src2html.pl tool from code2ebook:
  https://github.com/agentzh/code2ebook
-->

<html>
 <head>
  <title>utils/spark/SparkHistoryServerMetricsRetriever.scala - Spark Insight</title>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <style>
body {
    text-align: left;
    text-align-last: left;
}

code {
    font-family: consolas, monospace;
    line-height: 130%;
}


  </style>
 </head>
 <body>

  <h1>utils/spark/SparkHistoryServerMetricsRetriever.scala - Spark Insight</h1>
 <h2>Data types defined</h2>
 <ul class="toc">
<li><a href="#L14">SparkHistoryServerMetricsRetriever</a></li>
<li><a href="#L65">SparkHistoryServerMetricsRetriever</a></li>
</ul>
 <h2>Functions defined</h2>
 <ul class="toc">
<li><a href="#L36">buildRawSparkMetrics</a></li>
</ul>
 <h2>Source code</h2>

  <code>package com.microsoft.spark.insight.utils.spark<br/>
<br/>
import java.net.URI<br/>
<br/>
import scala.collection.immutable.ListMap<br/>
import scala.collection.parallel.ForkJoinTaskSupport<br/>
import scala.concurrent.forkjoin.ForkJoinPool<br/>
<br/>
/**<br/>
 * A Spark History Server based metrics retriever<br/>
 *<br/>
 * Will connect to a Spark History Server to <a href="../../cli/AppReportSets.scala.html#L44" title="cli/AppReportSets.scala:44">retrieve</a> application info using a [[<a href="../../fetcher/SparkRestClient.scala.html#L48" title="fetcher/SparkRestClient.scala:48">SparkRestClient</a>]]<br/>
 */<br/>
<a id="L14">&#x200c;</a>class <span class="linkable">SparkHistoryServerMetricsRetriever</span>(historyServerUri: URI) extends <a href="SparkMetricsRetriever.scala.html#L6" title="utils/spark/SparkMetricsRetriever.scala:6">SparkMetricsRetriever</a> {<br/>
&nbsp; private val client = new <a href="../../fetcher/SparkRestClient.scala.html#L48" title="fetcher/SparkRestClient.scala:48">SparkRestClient</a>(historyServerUri)<br/>
<br/>
&nbsp; // The default scala setting is 1 thread per core; We set a larger number as the parallel processing<br/>
&nbsp; // mainly waits for the REST response<br/>
&nbsp; private val folkJoinTaskSupport = new ForkJoinTaskSupport(<br/>
&nbsp; &nbsp; new ForkJoinPool(<a href="#L14" title="utils/spark/SparkHistoryServerMetricsRetriever.scala:14">SparkHistoryServerMetricsRetriever</a>.TARGET_THREAD_NUM))<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Retrieves the first application <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="fetcher/status/statusapiv1.scala:193">attempt</a> info for all of the applicationIds provided, and wraps them in a<br/>
&nbsp;&nbsp; * [[<a href="RawSparkMetrics.scala.html#L13" title="utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>]]<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param appIds ApplicationIds to fetch<br/>
&nbsp;&nbsp; * @return A sequence of wrapped metrics<br/>
&nbsp;&nbsp; */<br/>
&nbsp; override def <a href="../../cli/AppReportSets.scala.html#L44" title="cli/AppReportSets.scala:44">retrieve</a>(appIds: Seq[String]): Seq[<a href="RawSparkMetrics.scala.html#L13" title="utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>] = {<br/>
&nbsp; &nbsp; val parAppIds = appIds.par<br/>
<br/>
&nbsp; &nbsp; parAppIds.tasksupport = folkJoinTaskSupport<br/>
&nbsp; &nbsp; parAppIds.map(<a href="#L36" title="utils/spark/SparkHistoryServerMetricsRetriever.scala:36">buildRawSparkMetrics</a>).seq<br/>
&nbsp; }<br/>
<br/>
<a id="L36">&#x200c;</a>&nbsp; private def <span class="linkable">buildRawSparkMetrics</span>(<a href="RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>: String): <a href="RawSparkMetrics.scala.html#L13" title="utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a> = {<br/>
&nbsp; &nbsp; val appInfo = client.<a href="../../fetcher/SparkRestClient.scala.html#L156" title="fetcher/SparkRestClient.scala:156">getApplicationInfo</a>(<a href="RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>)<br/>
&nbsp; &nbsp; val attemptMap = appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L49" title="fetcher/status/statusapiv1.scala:49">attempts</a><br/>
&nbsp; &nbsp; &nbsp; .filter(_.<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="fetcher/status/statusapiv1.scala:59">attemptId</a>.isDefined)<br/>
&nbsp; &nbsp; &nbsp; .map(appAttempt =&gt; {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val appAttemptId = appAttempt.<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="fetcher/status/statusapiv1.scala:59">attemptId</a>.getOrElse(<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; throw new IllegalStateException(<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;Undefined <a href="../../fetcher/status/statusapiv1.scala.html#L59" title="fetcher/status/statusapiv1.scala:59">attemptId</a> found - should never be thrown since undefined <a href="../../fetcher/status/statusapiv1.scala.html#L49" title="fetcher/status/statusapiv1.scala:49">attempts</a> were already filtered&quot;))<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val envInfo = client.<a href="SparkRestClient.scala.html#L72" title="utils/spark/SparkRestClient.scala:72">getApplicationEnvironmentInfo</a>(<a href="RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>, appAttemptId)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; // Explicitly use a ListMap to preserve <a href="SparkAppReportMatcher.scala.html#L172" title="utils/spark/SparkAppReportMatcher.scala:172">ordering</a> - simplifies testing<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val jobDataMap = ListMap(client.<a href="../../fetcher/SparkRestClient.scala.html#L174" title="fetcher/SparkRestClient.scala:174">getJobDatas</a>(<a href="RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>, appAttemptId).map(jobData =&gt; jobData.<a href="../../fetcher/status/statusapiv1.scala.html#L104" title="fetcher/status/statusapiv1.scala:104">jobId</a> -&gt; jobData): _*)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val stageDataMap = client<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .<a href="SparkRestClient.scala.html#L96" title="utils/spark/SparkRestClient.scala:96">getStagesWithSummaries</a>(<a href="RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>, appAttemptId)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .groupBy(_.<a href="../../fetcher/status/statusapiv1.scala.html#L150" title="fetcher/status/statusapiv1.scala:150">stageId</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .mapValues(stageDatas =&gt; stageDatas.map(stageData =&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="fetcher/status/statusapiv1.scala:59">attemptId</a> -&gt; stageData).toMap)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; appAttemptId -&gt; <a href="RawSparkApplicationAttempt.scala.html#L14" title="utils/spark/RawSparkApplicationAttempt.scala:14">RawSparkApplicationAttempt</a>(appAttempt, envInfo, jobDataMap, stageDataMap)<br/>
&nbsp; &nbsp; &nbsp; })<br/>
&nbsp; &nbsp; &nbsp; .toMap<br/>
<br/>
&nbsp; &nbsp; <a href="RawSparkMetrics.scala.html#L13" title="utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>(appInfo, attemptMap)<br/>
&nbsp; }<br/>
}<br/>
<br/>
/**<br/>
 * Companion object of <a href="#L14" title="utils/spark/SparkHistoryServerMetricsRetriever.scala:14">SparkHistoryServerMetricsRetriever</a><br/>
 */<br/>
<a id="L65">&#x200c;</a>object <span class="linkable">SparkHistoryServerMetricsRetriever</span> {<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Setting number of threads for parallel collection processing<br/>
&nbsp;&nbsp; */<br/>
&nbsp; private val TARGET_THREAD_NUM: Int = 16<br/>
}<br/>
</code>

 </body>
</html>
