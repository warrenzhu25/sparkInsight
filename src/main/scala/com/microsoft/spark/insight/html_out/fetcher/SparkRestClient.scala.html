<!-- generated by the src2html.pl tool from code2ebook:
  https://github.com/agentzh/code2ebook
-->

<html>
 <head>
  <title>fetcher/SparkRestClient.scala - Spark Insight</title>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <style>
body {
    text-align: left;
    text-align-last: left;
}

code {
    font-family: consolas, monospace;
    line-height: 130%;
}


  </style>
 </head>
 <body>

  <h1>fetcher/SparkRestClient.scala - Spark Insight</h1>
 <h2>Data types defined</h2>
 <ul class="toc">
<li><a href="#L48">SparkRestClient</a></li>
<li><a href="#L206">SparkRestClient</a></li>
</ul>
 <h2>Functions defined</h2>
 <ul class="toc">
<li><a href="#L56">fetchData</a></li>
<li><a href="#L229">get</a></li>
<li><a href="#L133">getApiTarget</a></li>
<li><a href="#L156">getApplicationInfo</a></li>
<li><a href="#L160">getApplicationLogs</a></li>
<li><a href="#L140">getApplicationMetaData</a></li>
<li><a href="#L200">getEnv</a></li>
<li><a href="#L184">getExecutorSummaries</a></li>
<li><a href="#L174">getJobDatas</a></li>
<li><a href="#L179">getStageDatas</a></li>
<li><a href="#L194">getTasks</a></li>
<li><a href="#L189">getTasksOfFailedStages</a></li>
<li><a href="#L98">readDataLocally</a></li>
<li><a href="#L126">spilt</a></li>
<li><a href="#L115">writeDataLocally</a></li>
</ul>
 <h2>Source code</h2>

  <code>/*<br/>
 * Copyright 2016 LinkedIn Corp.<br/>
 *<br/>
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not<br/>
 * use this file except in compliance with the License. You may obtain a copy of<br/>
 * the License at<br/>
 *<br/>
 * http://www.apache.org/licenses/LICENSE-2.0<br/>
 *<br/>
 * Unless required by applicable law or agreed to in writing, software<br/>
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT<br/>
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the<br/>
 * License for the specific language governing permissions and limitations under<br/>
 * the License.<br/>
 */<br/>
<br/>
package com.microsoft.spark.insight.fetcher<br/>
<br/>
import java.io.BufferedInputStream<br/>
import java.net.URI<br/>
import java.nio.file.{Files, Paths}<br/>
import java.text.SimpleDateFormat<br/>
import java.util.zip.ZipInputStream<br/>
import java.util.{Calendar, SimpleTimeZone}<br/>
<br/>
import com.fasterxml.jackson.databind.{DeserializationFeature, ObjectMapper}<br/>
import com.fasterxml.jackson.module.scala.DefaultScalaModule<br/>
import com.fasterxml.jackson.module.scala.experimental.ScalaObjectMapper<br/>
import com.microsoft.spark.insight.fetcher.<a href="status/statusapiv1.scala.html#L111" title="fetcher/status/statusapiv1.scala:111">status</a>._<br/>
import javax.ws.rs.client.{Client, ClientBuilder, WebTarget}<br/>
import javax.ws.rs.core.MediaType<br/>
import org.apache.log4j.Logger<br/>
import org.glassfish.jersey.client.ClientProperties<br/>
<br/>
import scala.concurrent.duration.{Duration, HOURS}<br/>
import scala.concurrent.{Await, ExecutionContext, Future}<br/>
import scala.io.Source<br/>
import scala.util.control.NonFatal<br/>
<br/>
/**<br/>
 * A client for getting data from the Spark monitoring REST API,<br/>
 * e.g. &lt;https://spark.apache.org/docs/1.4.1/monitoring.views.html#rest-api&gt;.<br/>
 *<br/>
 * Jersey classloading seems to be brittle (at least when testing in the console),<br/>
 * so some of the implementation is non-lazy<br/>
 * or synchronous when needed.<br/>
 */<br/>
<a id="L48">&#x200c;</a>class <span class="linkable">SparkRestClient</span> {<br/>
<br/>
&nbsp; import <a href="#L48" title="fetcher/SparkRestClient.scala:48">SparkRestClient</a>._<br/>
<br/>
&nbsp; private val logger: Logger = Logger.getLogger(classOf[<a href="#L48" title="fetcher/SparkRestClient.scala:48">SparkRestClient</a>])<br/>
<br/>
&nbsp; private val client: Client = ClientBuilder.newClient()<br/>
<br/>
<a id="L56">&#x200c;</a>&nbsp; def <span class="linkable">fetchData</span>(trackingUrl: String)(<br/>
&nbsp; &nbsp; implicit ec: ExecutionContext<br/>
&nbsp; ): Future[<a href="SparkApplicationData.scala.html#L21" title="fetcher/SparkApplicationData.scala:21">SparkApplicationData</a>] = {<br/>
&nbsp; &nbsp; val (historyServerUri, <a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>) = <a href="#L126" title="fetcher/SparkRestClient.scala:126">spilt</a>(trackingUrl)<br/>
<br/>
&nbsp; &nbsp; Future {<br/>
&nbsp; &nbsp; &nbsp; val localData = <a href="#L98" title="fetcher/SparkRestClient.scala:98">readDataLocally</a>(<a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>)<br/>
<br/>
&nbsp; &nbsp; &nbsp; if (localData.nonEmpty) {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; localData.<a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a><br/>
&nbsp; &nbsp; &nbsp; } else {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val (applicationInfo, env, attemptTarget) = <a href="#L140" title="fetcher/SparkRestClient.scala:140">getApplicationMetaData</a>(<a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>, historyServerUri)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val futureJobDatas = Future {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L174" title="fetcher/SparkRestClient.scala:174">getJobDatas</a>(attemptTarget)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val futureStageDatas = Future {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L179" title="fetcher/SparkRestClient.scala:179">getStageDatas</a>(attemptTarget)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val futureExecutorSummaries = Future {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L184" title="fetcher/SparkRestClient.scala:184">getExecutorSummaries</a>(attemptTarget)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val futureTasks = Future {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L189" title="fetcher/SparkRestClient.scala:189">getTasksOfFailedStages</a>(attemptTarget)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val appData = <a href="SparkApplicationData.scala.html#L21" title="fetcher/SparkApplicationData.scala:21">SparkApplicationData</a>(<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>,<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; env.sparkProperties.map(p =&gt; p._1 -&gt; p._2).toMap,<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; applicationInfo,<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Await.result(futureJobDatas, DEFAULT_TIMEOUT),<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Await.result(futureStageDatas, DEFAULT_TIMEOUT),<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Await.result(futureExecutorSummaries, DEFAULT_TIMEOUT),<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Await.result(futureTasks, DEFAULT_TIMEOUT)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; )<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L115" title="fetcher/SparkRestClient.scala:115">writeDataLocally</a>(appData)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; appData<br/>
&nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
<a id="L98">&#x200c;</a>&nbsp; private def <span class="linkable">readDataLocally</span>(<a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>: String): Option[<a href="SparkApplicationData.scala.html#L21" title="fetcher/SparkApplicationData.scala:21">SparkApplicationData</a>] = {<br/>
&nbsp; &nbsp; val path = s&quot;&quot;&quot;D:\\<a href="../SparkInsight.scala.html#L13" title="SparkInsight.scala:13">SparkInsight</a>\\$<a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>.json&quot;&quot;&quot;<br/>
<br/>
&nbsp; &nbsp; if (!Files.exists(Paths.<a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(path))) {<br/>
&nbsp; &nbsp; &nbsp; return None<br/>
&nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; val bufferedSource = Source.fromFile(path)<br/>
<br/>
&nbsp; &nbsp; try {<br/>
&nbsp; &nbsp; &nbsp; logger.info(s&quot;Reading data from $path&quot;)<br/>
&nbsp; &nbsp; &nbsp; Some(SparkRestObjectMapper.readValue(bufferedSource.mkString, classOf[<a href="SparkApplicationData.scala.html#L21" title="fetcher/SparkApplicationData.scala:21">SparkApplicationData</a>]))<br/>
&nbsp; &nbsp; } finally {<br/>
&nbsp; &nbsp; &nbsp; bufferedSource.close()<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
<a id="L115">&#x200c;</a>&nbsp; private def <span class="linkable">writeDataLocally</span>(sparkApplicationData: <a href="SparkApplicationData.scala.html#L21" title="fetcher/SparkApplicationData.scala:21">SparkApplicationData</a>) = {<br/>
&nbsp; &nbsp; val file = s&quot;&quot;&quot;D:\\<a href="../SparkInsight.scala.html#L13" title="SparkInsight.scala:13">SparkInsight</a>\\${sparkApplicationData.<a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>}.json&quot;&quot;&quot;<br/>
&nbsp; &nbsp; val path = Paths.<a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(file)<br/>
&nbsp; &nbsp; if (!Files.exists(path)) {<br/>
&nbsp; &nbsp; &nbsp; logger.info(s&quot;Writing data from $file&quot;)<br/>
&nbsp; &nbsp; &nbsp; Files.createDirectories(path.getParent)<br/>
&nbsp; &nbsp; &nbsp; Files.createFile(path)<br/>
&nbsp; &nbsp; &nbsp; Files.write(path, SparkRestObjectMapper.writeValueAsBytes(sparkApplicationData))<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
<a id="L126">&#x200c;</a>&nbsp; private def <span class="linkable">spilt</span>(trackingUrl: String): (String, String) = {<br/>
&nbsp; &nbsp; val uri = new URI(trackingUrl)<br/>
&nbsp; &nbsp; val <a href="status/statusapiv1.scala.html#L196" title="fetcher/status/statusapiv1.scala:196">host</a> = s&quot;${uri.getScheme}://${uri.getHost}:${uri.getPort}&quot;<br/>
&nbsp; &nbsp; val <a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a> = uri.getPath.split('/').find(_.startsWith(&quot;application_&quot;)).getOrElse(&quot;&quot;)<br/>
&nbsp; &nbsp; (<a href="status/statusapiv1.scala.html#L196" title="fetcher/status/statusapiv1.scala:196">host</a>, <a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>)<br/>
&nbsp; }<br/>
<br/>
<a id="L133">&#x200c;</a>&nbsp; private def <span class="linkable">getApiTarget</span>(historyServerUri: String): WebTarget =<br/>
&nbsp; &nbsp; client<br/>
&nbsp; &nbsp; &nbsp; .property(ClientProperties.CONNECT_TIMEOUT, CONNECTION_TIMEOUT)<br/>
&nbsp; &nbsp; &nbsp; .property(ClientProperties.READ_TIMEOUT, READ_TIMEOUT)<br/>
&nbsp; &nbsp; &nbsp; .target(historyServerUri)<br/>
&nbsp; &nbsp; &nbsp; .path(API_V1_MOUNT_PATH)<br/>
<br/>
<a id="L140">&#x200c;</a>&nbsp; private def <span class="linkable">getApplicationMetaData</span>(<a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>: String, historyServerUri: String):<br/>
&nbsp; (<a href="status/statusapiv1.scala.html#L307" title="fetcher/status/statusapiv1.scala:307">ApplicationInfoImpl</a>, <a href="status/statusapiv1.scala.html#L52" title="fetcher/status/statusapiv1.scala:52">ApplicationEnvironmentInfo</a>, WebTarget) = {<br/>
&nbsp; &nbsp; val apiTarget = <a href="#L133" title="fetcher/SparkRestClient.scala:133">getApiTarget</a>(historyServerUri)<br/>
&nbsp; &nbsp; val appTarget = apiTarget.path(s&quot;applications/${<a href="../utils/spark/RawSparkMetrics.scala.html#L31" title="utils/spark/RawSparkMetrics.scala:31">appId</a>}&quot;)<br/>
&nbsp; &nbsp; logger.info(s&quot;calling REST API at ${appTarget.getUri}&quot;)<br/>
<br/>
&nbsp; &nbsp; val applicationInfo = <a href="#L156" title="fetcher/SparkRestClient.scala:156">getApplicationInfo</a>(appTarget)<br/>
<br/>
&nbsp; &nbsp; val lastAttemptId = applicationInfo.<a href="status/statusapiv1.scala.html#L49" title="fetcher/status/statusapiv1.scala:49">attempts</a>.maxBy {<br/>
&nbsp; &nbsp; &nbsp; _.<a href="status/statusapiv1.scala.html#L60" title="fetcher/status/statusapiv1.scala:60">startTime</a><br/>
&nbsp; &nbsp; }.<a href="status/statusapiv1.scala.html#L59" title="fetcher/status/statusapiv1.scala:59">attemptId</a><br/>
&nbsp; &nbsp; val attemptTarget = lastAttemptId.map(appTarget.path).getOrElse(appTarget)<br/>
&nbsp; &nbsp; val applicationEnvironmentInfo = <a href="#L200" title="fetcher/SparkRestClient.scala:200">getEnv</a>(attemptTarget)<br/>
&nbsp; &nbsp; (applicationInfo, applicationEnvironmentInfo, attemptTarget)<br/>
&nbsp; }<br/>
<br/>
<a id="L156">&#x200c;</a>&nbsp; private def <span class="linkable">getApplicationInfo</span>(appTarget: WebTarget): <a href="status/statusapiv1.scala.html#L307" title="fetcher/status/statusapiv1.scala:307">ApplicationInfoImpl</a> = {<br/>
&nbsp; &nbsp; <a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(appTarget, SparkRestObjectMapper.readValue[<a href="status/statusapiv1.scala.html#L307" title="fetcher/status/statusapiv1.scala:307">ApplicationInfoImpl</a>])<br/>
&nbsp; }<br/>
<br/>
<a id="L160">&#x200c;</a>&nbsp; private[fetcher] def <span class="linkable">getApplicationLogs</span>(logTarget: WebTarget): ZipInputStream = {<br/>
&nbsp; &nbsp; try {<br/>
&nbsp; &nbsp; &nbsp; val is = logTarget.request(MediaType.APPLICATION_OCTET_STREAM)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .<a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(classOf[java.io.InputStream])<br/>
&nbsp; &nbsp; &nbsp; new ZipInputStream(new BufferedInputStream(is))<br/>
&nbsp; &nbsp; } catch {<br/>
&nbsp; &nbsp; &nbsp; case NonFatal(e) =&gt; {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; logger.error(s&quot;error reading logs ${logTarget.getUri}. Exception Message = &quot; + e.<a href="../heuristics/StageAnalyzer.scala.html#L519" title="heuristics/StageAnalyzer.scala:519">getMessage</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; logger.debug(e)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; throw e<br/>
&nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
<a id="L174">&#x200c;</a>&nbsp; private def <span class="linkable">getJobDatas</span>(attemptTarget: WebTarget): Seq[<a href="status/statusapiv1.scala.html#L354" title="fetcher/status/statusapiv1.scala:354">JobDataImpl</a>] = {<br/>
&nbsp; &nbsp; val target = attemptTarget.path(&quot;jobs&quot;)<br/>
&nbsp; &nbsp; <a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(target, SparkRestObjectMapper.readValue[Seq[<a href="status/statusapiv1.scala.html#L354" title="fetcher/status/statusapiv1.scala:354">JobDataImpl</a>]])<br/>
&nbsp; }<br/>
<br/>
<a id="L179">&#x200c;</a>&nbsp; private def <span class="linkable">getStageDatas</span>(attemptTarget: WebTarget): Seq[<a href="status/statusapiv1.scala.html#L399" title="fetcher/status/statusapiv1.scala:399">StageDataImpl</a>] = {<br/>
&nbsp; &nbsp; val target = attemptTarget.path(&quot;stages&quot;)<br/>
&nbsp; &nbsp; <a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(target, SparkRestObjectMapper.readValue[Seq[<a href="status/statusapiv1.scala.html#L399" title="fetcher/status/statusapiv1.scala:399">StageDataImpl</a>]])<br/>
&nbsp; }<br/>
<br/>
<a id="L184">&#x200c;</a>&nbsp; private def <span class="linkable">getExecutorSummaries</span>(attemptTarget: WebTarget): Seq[<a href="status/statusapiv1.scala.html#L330" title="fetcher/status/statusapiv1.scala:330">ExecutorSummaryImpl</a>] = {<br/>
&nbsp; &nbsp; val target = attemptTarget.path(&quot;allexecutors&quot;)<br/>
&nbsp; &nbsp; <a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(target, SparkRestObjectMapper.readValue[Seq[<a href="status/statusapiv1.scala.html#L330" title="fetcher/status/statusapiv1.scala:330">ExecutorSummaryImpl</a>]])<br/>
&nbsp; }<br/>
<br/>
<a id="L189">&#x200c;</a>&nbsp; private def <span class="linkable">getTasksOfFailedStages</span>(attemptTarget: WebTarget): Map[String, Seq[<a href="status/statusapiv1.scala.html#L440" title="fetcher/status/statusapiv1.scala:440">TaskDataImpl</a>]] = {<br/>
&nbsp; &nbsp; val stageDatas = <a href="#L194" title="fetcher/SparkRestClient.scala:194">getTasks</a>(attemptTarget)<br/>
&nbsp; &nbsp; stageDatas.map(s =&gt; s&quot;${s.<a href="status/statusapiv1.scala.html#L150" title="fetcher/status/statusapiv1.scala:150">stageId</a>}-${s.<a href="status/statusapiv1.scala.html#L59" title="fetcher/status/statusapiv1.scala:59">attemptId</a>}&quot; -&gt; s.<a href="status/statusapiv1.scala.html#L180" title="fetcher/status/statusapiv1.scala:180">tasks</a>.values.toSeq).toMap<br/>
&nbsp; }<br/>
<br/>
<a id="L194">&#x200c;</a>&nbsp; private def <span class="linkable">getTasks</span>(attemptTarget: WebTarget): Seq[<a href="status/statusapiv1.scala.html#L148" title="fetcher/status/statusapiv1.scala:148">StageData</a>] = {<br/>
&nbsp; &nbsp; val target = attemptTarget.path(s&quot;allTasks&quot;)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .queryParam(&quot;<a href="status/statusapiv1.scala.html#L111" title="fetcher/status/statusapiv1.scala:111">status</a>&quot;, &quot;failed&quot;)<br/>
&nbsp; &nbsp; <a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(target, SparkRestObjectMapper.readValue[Seq[<a href="status/statusapiv1.scala.html#L399" title="fetcher/status/statusapiv1.scala:399">StageDataImpl</a>]])<br/>
&nbsp; }<br/>
<br/>
<a id="L200">&#x200c;</a>&nbsp; private def <span class="linkable">getEnv</span>(attemptTarget: WebTarget): <a href="status/statusapiv1.scala.html#L52" title="fetcher/status/statusapiv1.scala:52">ApplicationEnvironmentInfo</a> = {<br/>
&nbsp; &nbsp; val target = attemptTarget.path(&quot;environment&quot;)<br/>
&nbsp; &nbsp; <a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(target, SparkRestObjectMapper.readValue[<a href="status/statusapiv1.scala.html#L52" title="fetcher/status/statusapiv1.scala:52">ApplicationEnvironmentInfo</a>])<br/>
&nbsp; }<br/>
}<br/>
<br/>
<a id="L206">&#x200c;</a>object <span class="linkable">SparkRestClient</span> {<br/>
&nbsp; val API_V1_MOUNT_PATH = &quot;api/v1&quot;<br/>
&nbsp; val IN_PROGRESS = &quot;.inprogress&quot;<br/>
&nbsp; val DEFAULT_TIMEOUT = Duration(1, HOURS);<br/>
&nbsp; val CONNECTION_TIMEOUT = 60000<br/>
&nbsp; val READ_TIMEOUT = 60000<br/>
&nbsp; val logger: Logger = Logger.getLogger(<a href="#L48" title="fetcher/SparkRestClient.scala:48">SparkRestClient</a>.getClass)<br/>
<br/>
&nbsp; val SparkRestObjectMapper = {<br/>
&nbsp; &nbsp; val dateFormat = {<br/>
&nbsp; &nbsp; &nbsp; val iso8601 = new SimpleDateFormat(&quot;yyyy-MM-dd'T'HH:mm:ss.SSS'GMT'&quot;)<br/>
&nbsp; &nbsp; &nbsp; val cal = Calendar.getInstance(new SimpleTimeZone(0, &quot;GMT&quot;))<br/>
&nbsp; &nbsp; &nbsp; iso8601.setCalendar(cal)<br/>
&nbsp; &nbsp; &nbsp; iso8601<br/>
&nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; val objectMapper = new ObjectMapper() with ScalaObjectMapper<br/>
&nbsp; &nbsp; objectMapper.setDateFormat(dateFormat)<br/>
&nbsp; &nbsp; objectMapper.registerModule(DefaultScalaModule)<br/>
&nbsp; &nbsp; objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)<br/>
&nbsp; &nbsp; objectMapper<br/>
&nbsp; }<br/>
<br/>
<a id="L229">&#x200c;</a>&nbsp; def <span class="linkable">get</span>[T](webTarget: WebTarget, converter: String =&gt; T): T =<br/>
&nbsp; &nbsp; try {<br/>
&nbsp; &nbsp; &nbsp; converter(webTarget.request(MediaType.APPLICATION_JSON).<a href="#L229" title="fetcher/SparkRestClient.scala:229">get</a>(classOf[String]))<br/>
&nbsp; &nbsp; } catch {<br/>
&nbsp; &nbsp; &nbsp; case NonFatal(e) =&gt; {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; logger.error(s&quot;error fetching ${webTarget.getUri}. Exception Message = &quot; + e.<a href="../heuristics/StageAnalyzer.scala.html#L519" title="heuristics/StageAnalyzer.scala:519">getMessage</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; logger.debug(e)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; throw e<br/>
&nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; }<br/>
}<br/>
</code>

 </body>
</html>
