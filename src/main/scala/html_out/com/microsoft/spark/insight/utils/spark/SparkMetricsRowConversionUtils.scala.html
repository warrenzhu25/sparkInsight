<!-- generated by the src2html.pl tool from code2ebook:
  https://github.com/agentzh/code2ebook
-->

<html>
 <head>
  <title>com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala - Spark Insight</title>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <style>
body {
    text-align: left;
    text-align-last: left;
}

code {
    font-family: consolas, monospace;
    line-height: 130%;
}


  </style>
 </head>
 <body>

  <h1>com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala - Spark Insight</h1>
 <h2>Data types defined</h2>
 <ul class="toc">
<li><a href="#L215">FieldNamePair</a></li>
<li><a href="#L217">FieldNamePair</a></li>
<li><a href="#L28">SparkMetricsRowConversionUtils</a></li>
</ul>
 <h2>Functions defined</h2>
 <ul class="toc">
<li><a href="#L194">apply</a></li>
<li><a href="#L218">apply</a></li>
<li><a href="#L169">assignFieldsFromRow</a></li>
<li><a href="#L40">convert</a></li>
<li><a href="#L166">createEmptyInstance</a></li>
<li><a href="#L182">createInstanceAndPopulate</a></li>
<li><a href="#L205">createInstanceAndPopulateToType</a></li>
<li><a href="#L185">createTypedInstanceAndPopulate</a></li>
<li><a href="#L126">extractValue</a></li>
<li><a href="#L225">getField</a></li>
<li><a href="#L110">getFieldType</a></li>
<li><a href="#L244">getRow</a></li>
<li><a href="#L246">getRowSeq</a></li>
<li><a href="#L258">getRowSeqAsMap</a></li>
<li><a href="#L242">getValue</a></li>
<li><a href="#L202">populateFieldFromNestedRow</a></li>
<li><a href="#L146">setField</a></li>
<li><a href="#L221">stringToFieldNamePair</a></li>
<li><a href="#L223">stringsToFieldNamePairs</a></li>
<li><a href="#L235">transformValue</a></li>
<li><a href="#L190">typeToTypeTag</a></li>
</ul>
 <h2>Source code</h2>

  <code>package com.microsoft.spark.insight.utils.spark<br/>
<br/>
import java.util.Date<br/>
<br/>
import com.microsoft.spark.insight.fetcher.<a href="../../fetcher/status/statusapiv1.scala.html#L111" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:111">status</a>.<a href="../../fetcher/status/statusapiv1.scala.html#L282" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:282">ExecutorMetricDistributions</a><br/>
import com.microsoft.spark.insight.utils.spark.<a href="RawSparkApplicationAttempt.scala.html#L14" title="com/microsoft/spark/insight/utils/spark/RawSparkApplicationAttempt.scala:14">RawSparkApplicationAttempt</a>.{JobDataMap, StageDataMap}<br/>
import com.microsoft.spark.insight.utils.spark.<a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>.AppAttemptId<br/>
import org.apache.commons.lang3.math.NumberUtils<br/>
import org.apache.spark.JobExecutionStatus<br/>
import org.apache.spark.sql.Row<br/>
import org.apache.spark.<a href="../../fetcher/status/statusapiv1.scala.html#L111" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:111">status</a>.api.v1._<br/>
import org.slf4j.{Logger, LoggerFactory}<br/>
import sun.misc.Unsafe<br/>
<br/>
import scala.reflect.api._<br/>
import scala.util.Try<br/>
<br/>
/**<br/>
 * A conversion utility for parsing a Spark Row containing an STP (Spark Tracking Pipeline) record (from<br/>
 * dalids://u_griddev.sparkmetrics) into a [[<a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>]] container<br/>
 * &lt;p&gt;<br/>
 * The lists of fields below define the conversion from fields in STP to fields in SHS structures. If fields are added<br/>
 * to STP and are desired in the SHS structures, the lists should be updated accordingly.<br/>
 * &lt;p&gt;<br/>
 * This is a temporary utility that will be replaced later once STS (Spark Tracking Service) will go live and replace<br/>
 * STP<br/>
 */<br/>
<a id="L28">&#x200c;</a>object <span class="linkable">SparkMetricsRowConversionUtils</span> {<br/>
&nbsp; val LOGGER: Logger = LoggerFactory.getLogger(<a href="#L28" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:28">SparkMetricsRowConversionUtils</a>.getClass)<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * A utility method for parsing a Spark Row containing an STP record (from dalids://u_griddev.sparkmetrics) into a<br/>
&nbsp;&nbsp; * [[<a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>]] container.<br/>
&nbsp;&nbsp; * Since all of the SHS structures (e.g. [[<a href="../../fetcher/status/statusapiv1.scala.html#L148" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:148">StageData</a>]]) do not expose a public c'tor, we use reflection <a href="../../cli/frontend/package.scala.html#L27" title="com/microsoft/spark/insight/cli/frontend/package.scala:27">black</a> magic<br/>
&nbsp;&nbsp; * to reconstruct and populate the structures<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param sparkMetrics a Spark Row containing an STP<br/>
&nbsp;&nbsp; * @return a <a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a> container<br/>
&nbsp;&nbsp; */<br/>
<a id="L40">&#x200c;</a>&nbsp; def <span class="linkable">convert</span>(sparkMetrics: Row): <a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a> = {<br/>
&nbsp; &nbsp; val appInfo: <a href="../../fetcher/status/statusapiv1.scala.html#L46" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:46">ApplicationInfo</a> = {<br/>
&nbsp; &nbsp; &nbsp; // An STP record only represents a single application <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a>. This is less of a concern as multi-<a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a> apps are<br/>
&nbsp; &nbsp; &nbsp; // unusual in GRID. Collect the single <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a> info and populate the array with it.<br/>
&nbsp; &nbsp; &nbsp; val applicationAttemptInfo = <a href="#L185" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:185">createTypedInstanceAndPopulate</a>[<a href="../../fetcher/status/statusapiv1.scala.html#L58" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:58">ApplicationAttemptInfo</a>](sparkMetrics)<br/>
<br/>
&nbsp; &nbsp; &nbsp; val appInfo = <a href="#L185" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:185">createTypedInstanceAndPopulate</a>[<a href="../../fetcher/status/statusapiv1.scala.html#L46" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:46">ApplicationInfo</a>](sparkMetrics)<br/>
&nbsp; &nbsp; &nbsp; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(appInfo, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>&quot;, Seq(applicationAttemptInfo))<br/>
&nbsp; &nbsp; &nbsp; appInfo<br/>
&nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; val appAttemptMap: Map[AppAttemptId, <a href="RawSparkApplicationAttempt.scala.html#L14" title="com/microsoft/spark/insight/utils/spark/RawSparkApplicationAttempt.scala:14">RawSparkApplicationAttempt</a>] = {<br/>
&nbsp; &nbsp; &nbsp; val applicationEnvironmentInfo: <a href="../../fetcher/status/statusapiv1.scala.html#L52" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:52">ApplicationEnvironmentInfo</a> = {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val applicationEnvironmentInfo = <a href="#L185" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:185">createTypedInstanceAndPopulate</a>[<a href="../../fetcher/status/statusapiv1.scala.html#L52" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:52">ApplicationEnvironmentInfo</a>](sparkMetrics)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(applicationEnvironmentInfo, &quot;sparkProperties&quot;, <a href="#L258" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:258">getRowSeqAsMap</a>(sparkMetrics, &quot;sparkproperties&quot;).toSeq)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(applicationEnvironmentInfo, &quot;systemProperties&quot;, <a href="#L258" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:258">getRowSeqAsMap</a>(sparkMetrics, &quot;systemproperties&quot;).toSeq)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(applicationEnvironmentInfo, &quot;classpathEntries&quot;, <a href="#L258" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:258">getRowSeqAsMap</a>(sparkMetrics, &quot;classpathentries&quot;).toSeq)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L202" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:202">populateFieldFromNestedRow</a>(&quot;runtime&quot;, sparkMetrics, applicationEnvironmentInfo)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; applicationEnvironmentInfo<br/>
&nbsp; &nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; &nbsp; val jobDataMap: JobDataMap = <a href="#L246" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:246">getRowSeq</a>(sparkMetrics, &quot;jobs&quot;)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .getOrElse(Seq.empty)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .map(jobRow =&gt; {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; val jobData = <a href="#L185" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:185">createTypedInstanceAndPopulate</a>[<a href="../../fetcher/status/statusapiv1.scala.html#L103" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:103">JobData</a>](jobRow)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(jobData, &quot;killedTasksSummary&quot;, <a href="#L258" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:258">getRowSeqAsMap</a>[Int](jobRow, &quot;killedtaskssummary&quot;))<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; jobData<br/>
&nbsp; &nbsp; &nbsp; &nbsp; })<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .map(jobData =&gt; jobData.<a href="../../fetcher/status/statusapiv1.scala.html#L104" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:104">jobId</a> -&gt; jobData)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .toMap<br/>
<br/>
&nbsp; &nbsp; &nbsp; val stageDataMap: StageDataMap = <a href="#L246" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:246">getRowSeq</a>(sparkMetrics, &quot;stages&quot;)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .getOrElse(Seq.empty)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .map(stageRow =&gt; {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; val stageData = <a href="#L185" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:185">createTypedInstanceAndPopulate</a>[<a href="../../fetcher/status/statusapiv1.scala.html#L148" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:148">StageData</a>](stageRow)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; val <a href="../../fetcher/status/statusapiv1.scala.html#L179" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:179">accumulatorUpdates</a> = <a href="#L246" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:246">getRowSeq</a>(stageRow, &quot;accumulatorupdates&quot;)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .getOrElse(Seq.empty)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .map(<a href="#L185" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:185">createTypedInstanceAndPopulate</a>[<a href="../../fetcher/status/statusapiv1.scala.html#L301" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:301">AccumulableInfo</a>])<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(stageData, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L179" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:179">accumulatorUpdates</a>&quot;, <a href="../../fetcher/status/statusapiv1.scala.html#L179" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:179">accumulatorUpdates</a>)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L244" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:244">getRow</a>(stageRow, &quot;tasksummary&quot;).foreach(taskSummaryRow =&gt; {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; val <a href="../../fetcher/status/statusapiv1.scala.html#L187" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:187">taskSummary</a> = <a href="#L185" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:185">createTypedInstanceAndPopulate</a>[<a href="../../fetcher/status/statusapiv1.scala.html#L238" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:238">TaskMetricDistributions</a>](taskSummaryRow)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(stageData, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L187" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:187">taskSummary</a>&quot;, Option(<a href="../../fetcher/status/statusapiv1.scala.html#L187" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:187">taskSummary</a>))<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L202" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:202">populateFieldFromNestedRow</a>(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L212" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:212">inputMetrics</a>&quot;, taskSummaryRow, <a href="../../fetcher/status/statusapiv1.scala.html#L187" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:187">taskSummary</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L202" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:202">populateFieldFromNestedRow</a>(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L213" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:213">outputMetrics</a>&quot;, taskSummaryRow, <a href="../../fetcher/status/statusapiv1.scala.html#L187" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:187">taskSummary</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L202" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:202">populateFieldFromNestedRow</a>(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L214" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:214">shuffleReadMetrics</a>&quot;, taskSummaryRow, <a href="../../fetcher/status/statusapiv1.scala.html#L187" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:187">taskSummary</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L202" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:202">populateFieldFromNestedRow</a>(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L215" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:215">shuffleWriteMetrics</a>&quot;, taskSummaryRow, <a href="../../fetcher/status/statusapiv1.scala.html#L187" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:187">taskSummary</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; })<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="#L202" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:202">populateFieldFromNestedRow</a>(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L188" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:188">executorMetricsSummary</a>&quot;, stageRow, stageData)<br/>
<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; stageData<br/>
&nbsp; &nbsp; &nbsp; &nbsp; })<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .groupBy(_.<a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .mapValues(_.map(stageData =&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a> -&gt; stageData).toMap)<br/>
<br/>
&nbsp; &nbsp; &nbsp; Map(<br/>
&nbsp; &nbsp; &nbsp; &nbsp; appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>.head.<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a><br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .getOrElse(throw new IllegalArgumentException(&quot;No application <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a> ID was found&quot;)) -&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a href="RawSparkApplicationAttempt.scala.html#L14" title="com/microsoft/spark/insight/utils/spark/RawSparkApplicationAttempt.scala:14">RawSparkApplicationAttempt</a>(appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>.head, applicationEnvironmentInfo, jobDataMap, stageDataMap))<br/>
&nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; <a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>(appInfo, appAttemptMap)<br/>
&nbsp; }<br/>
<br/>
&nbsp; import scala.reflect.runtime.universe.{TermName, Type, TypeTag, typeOf}<br/>
<br/>
<a id="L110">&#x200c;</a>&nbsp; private def <span class="linkable">getFieldType</span>[T](typeTag: TypeTag[T], fieldName: String): Type = {<br/>
&nbsp; &nbsp; try {<br/>
&nbsp; &nbsp; &nbsp; typeTag.tpe.member(TermName(fieldName)).info.resultType<br/>
&nbsp; &nbsp; } catch {<br/>
&nbsp; &nbsp; &nbsp; case e: Exception =&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; throw new IllegalArgumentException(s&quot;Unable to <a href="../../cli/AppReportSets.scala.html#L44" title="com/microsoft/spark/insight/cli/AppReportSets.scala:44">retrieve</a> field type for field $fieldName in ${typeTag.tpe}&quot;, e)<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Recursively <a href="#L40" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:40">convert</a> the <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> onto the desired [[Type]]<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param destType type to covert the <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> to<br/>
&nbsp;&nbsp; * @param <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> to <a href="#L40" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:40">convert</a><br/>
&nbsp;&nbsp; * @return converted <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> in the desired [[Type]]<br/>
&nbsp;&nbsp; */<br/>
<a id="L126">&#x200c;</a>&nbsp; private def <span class="linkable">extractValue</span>(destType: Type, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: Any): Any = (destType, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>) match {<br/>
&nbsp; &nbsp; case (t, null) if t &lt;:&lt; typeOf[Option[_]] =&gt; None<br/>
&nbsp; &nbsp; case (t, _) if t &lt;:&lt; typeOf[Option[_]] =&gt; Option(<a href="#L126" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:126">extractValue</a>(destType.typeArgs.head, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>))<br/>
&nbsp; &nbsp; case (t, null) if t =:= typeOf[Long] =&gt; 0L<br/>
&nbsp; &nbsp; case (t, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: Any) if t =:= typeOf[String] =&gt; <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>.toString<br/>
&nbsp; &nbsp; case (t, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: String) if t =:= typeOf[Date] =&gt; <a href="SparkJsonUtils.scala.html#L14" title="com/microsoft/spark/insight/utils/spark/SparkJsonUtils.scala:14">SparkJsonUtils</a>.DATE_FORMAT.parse(<a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>)<br/>
&nbsp; &nbsp; case (t, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: Number) if t =:= typeOf[Int] =&gt; <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>.intValue()<br/>
&nbsp; &nbsp; case (t, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: Long) if t =:= typeOf[Long] =&gt; <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a><br/>
&nbsp; &nbsp; case (t, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: String) if t =:= typeOf[JobExecutionStatus] =&gt; JobExecutionStatus.fromString(<a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>)<br/>
&nbsp; &nbsp; case (t, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: String) if t =:= typeOf[StageStatus] =&gt; StageStatus.fromString(<a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>)<br/>
&nbsp; &nbsp; case _ =&gt; <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a><br/>
&nbsp; }<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * An incredibly hacky method for setting immutable fields<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param obj object with the field to be set<br/>
&nbsp;&nbsp; * @param fieldName field <a href="../../fetcher/status/statusapiv1.scala.html#L48" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:48">name</a> to modify<br/>
&nbsp;&nbsp; * @param <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> to set for the given field <a href="../../fetcher/status/statusapiv1.scala.html#L48" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:48">name</a><br/>
&nbsp;&nbsp; */<br/>
<a id="L146">&#x200c;</a>&nbsp; private def <span class="linkable">setField</span>[T](obj: Any, fieldName: String, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: Any)(implicit typeTag: TypeTag[T]): Unit = {<br/>
&nbsp; &nbsp; val clazz = obj.getClass<br/>
&nbsp; &nbsp; Try(clazz.getDeclaredField(fieldName)).toOption match {<br/>
&nbsp; &nbsp; &nbsp; case Some(field) =&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; // Retrieve the destination member type and <a href="#L40" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:40">convert</a> <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> if necessary<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val valueToSet = <a href="#L126" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:126">extractValue</a>(<a href="#L110" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:110">getFieldType</a>(typeTag, fieldName), <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; try {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; field.setAccessible(true)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; clazz.getMethod(fieldName).invoke(obj) // force init in case it's a lazy val<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; field.set(obj, valueToSet) // overwrite <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a><br/>
&nbsp; &nbsp; &nbsp; &nbsp; } catch {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; case e: Exception =&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; throw new IllegalArgumentException(s&quot;Failed to set field '$fieldName' in class '$clazz'&quot;, e)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; &nbsp; case None =&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; throw new IllegalArgumentException(s&quot;Field $fieldName is not a member of ${typeTag.tpe}&quot;)<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
<a id="L166">&#x200c;</a>&nbsp; private def <span class="linkable">createEmptyInstance</span>[T](implicit typeTag: TypeTag[T]): Any =<br/>
&nbsp; &nbsp; Unsafe.getUnsafe.allocateInstance(typeTag.mirror.runtimeClass(typeTag.tpe))<br/>
<br/>
<a id="L169">&#x200c;</a>&nbsp; private def <span class="linkable">assignFieldsFromRow</span>[T](<br/>
&nbsp; &nbsp; &nbsp; fieldNamePairs: Seq[<a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>],<br/>
&nbsp; &nbsp; &nbsp; obj: Any,<br/>
&nbsp; &nbsp; &nbsp; row: Option[Row],<br/>
&nbsp; &nbsp; &nbsp; typeTag: TypeTag[T]): Any = {<br/>
&nbsp; &nbsp; row.foreach { row =&gt;<br/>
&nbsp; &nbsp; &nbsp; fieldNamePairs<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .map(fieldNamePair =&gt; (fieldNamePair.destFieldName, <a href="#L242" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:242">getValue</a>(row, fieldNamePair.sourceFieldName)))<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .foreach { case (fieldName, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>) =&gt; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(obj, fieldName, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>)(typeTag) }<br/>
&nbsp; &nbsp; }<br/>
&nbsp; &nbsp; obj<br/>
&nbsp; }<br/>
<br/>
<a id="L182">&#x200c;</a>&nbsp; private def <span class="linkable">createInstanceAndPopulate</span>[T](row: Option[Row])(implicit typeTag: TypeTag[T]): Any =<br/>
&nbsp; &nbsp; <a href="#L169" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:169">assignFieldsFromRow</a>(typeToFieldNames.getOrElse(typeTag.tpe, Seq.empty), <a href="#L166" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:166">createEmptyInstance</a>[T], row, typeTag)<br/>
<br/>
<a id="L185">&#x200c;</a>&nbsp; private def <span class="linkable">createTypedInstanceAndPopulate</span>[T](row: Row)(implicit typeTag: TypeTag[T]): T =<br/>
&nbsp; &nbsp; <a href="#L182" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:182">createInstanceAndPopulate</a>[T](Option(row)).asInstanceOf[T]<br/>
<br/>
&nbsp; private val mirror = scala.reflect.runtime.universe.runtimeMirror(getClass.getClassLoader)<br/>
<br/>
<a id="L190">&#x200c;</a>&nbsp; private def <span class="linkable">typeToTypeTag</span>[T](tpe: Type): TypeTag[T] =<br/>
&nbsp; &nbsp; TypeTag(<br/>
&nbsp; &nbsp; &nbsp; mirror,<br/>
&nbsp; &nbsp; &nbsp; new TypeCreator {<br/>
<a id="L194">&#x200c;</a>&nbsp; &nbsp; &nbsp; &nbsp; def <span class="linkable">apply</span>[U &lt;: Universe with Singleton](m: Mirror[U]): U#Type =<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (m eq mirror) {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tpe.asInstanceOf[U#Type]<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } else {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; throw new IllegalArgumentException(s&quot;Type tag defined in $mirror cannot be migrated to other mirrors.&quot;)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; &nbsp; })<br/>
<br/>
<a id="L202">&#x200c;</a>&nbsp; private def <span class="linkable">populateFieldFromNestedRow</span>[P](fieldNamePair: <a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>, row: Row, parentObj: P)(<br/>
&nbsp; &nbsp; &nbsp; implicit typeTag: TypeTag[P]): Unit = {<br/>
<br/>
<a id="L205">&#x200c;</a>&nbsp; &nbsp; def <span class="linkable">createInstanceAndPopulateToType</span>[T](memberType: Type): Any = memberType match {<br/>
&nbsp; &nbsp; &nbsp; case t if t &lt;:&lt; typeOf[Option[_]] =&gt; Option(<a href="#L205" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:205">createInstanceAndPopulateToType</a>(memberType.typeArgs.head))<br/>
&nbsp; &nbsp; &nbsp; case _ =&gt; <a href="#L182" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:182">createInstanceAndPopulate</a>(<a href="#L244" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:244">getRow</a>(row, fieldNamePair.sourceFieldName))(<a href="#L190" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:190">typeToTypeTag</a>(memberType))<br/>
&nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; // Retrieve the destination field type so the appropriate object can be instantiated<br/>
&nbsp; &nbsp; val obj = <a href="#L205" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:205">createInstanceAndPopulateToType</a>(<a href="#L110" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:110">getFieldType</a>(typeTag, fieldNamePair.destFieldName))<br/>
&nbsp; &nbsp; <a href="#L146" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:146">setField</a>(parentObj, fieldNamePair.destFieldName, obj)<br/>
&nbsp; }<br/>
<br/>
<a id="L215">&#x200c;</a>&nbsp; private case class <span class="linkable">FieldNamePair</span>(sourceFieldName: String, destFieldName: String)<br/>
<br/>
<a id="L217">&#x200c;</a>&nbsp; private object <span class="linkable">FieldNamePair</span> {<br/>
<a id="L218">&#x200c;</a>&nbsp; &nbsp; def <span class="linkable">apply</span>(destFieldName: String): <a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a> = <a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>(destFieldName.toLowerCase, destFieldName)<br/>
&nbsp; }<br/>
<br/>
<a id="L221">&#x200c;</a>&nbsp; implicit private def <span class="linkable">stringToFieldNamePair</span>(string: String): <a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a> = <a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>(string)<br/>
<br/>
<a id="L223">&#x200c;</a>&nbsp; implicit private def <span class="linkable">stringsToFieldNamePairs</span>(seq: Seq[String]): Seq[<a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>] = seq.map(<a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>(_))<br/>
<br/>
<a id="L225">&#x200c;</a>&nbsp; private def <span class="linkable">getField</span>(row: Row, fieldName: String): Option[Any] =<br/>
&nbsp; &nbsp; Try(row.fieldIndex(fieldName)).toOption.filterNot(row.isNullAt).map(row.getAs[Any])<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Extract more precisely typed values from [[Row]] fields: <a href="#L40" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:40">convert</a> [[String]]s to [[Number]]s and <a href="#L40" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:40">convert</a> empty<br/>
&nbsp;&nbsp; * strings to nulls.<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> object to <a href="#L40" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:40">convert</a><br/>
&nbsp;&nbsp; * @return transformed <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a><br/>
&nbsp;&nbsp; */<br/>
<a id="L235">&#x200c;</a>&nbsp; private def <span class="linkable">transformValue</span>(<a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: Any): Any = <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> match {<br/>
&nbsp; &nbsp; case seq: Seq[_] =&gt; seq.map(<a href="#L235" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:235">transformValue</a>)<br/>
&nbsp; &nbsp; case &quot;&quot; =&gt; null<br/>
&nbsp; &nbsp; case number: String if NumberUtils.isCreatable(number) =&gt; NumberUtils.createNumber(number)<br/>
&nbsp; &nbsp; case v =&gt; v<br/>
&nbsp; }<br/>
<br/>
<a id="L242">&#x200c;</a>&nbsp; private def <span class="linkable">getValue</span>(row: Row, fieldName: String): Any = <a href="#L225" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:225">getField</a>(row, fieldName).map(<a href="#L235" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:235">transformValue</a>).orNull<br/>
<br/>
<a id="L244">&#x200c;</a>&nbsp; private def <span class="linkable">getRow</span>(row: Row, fieldName: String): Option[Row] = <a href="#L225" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:225">getField</a>(row, fieldName).map(_.asInstanceOf[Row])<br/>
<br/>
<a id="L246">&#x200c;</a>&nbsp; private def <span class="linkable">getRowSeq</span>(row: Row, fieldName: String): Option[Seq[Row]] =<br/>
&nbsp; &nbsp; <a href="#L225" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:225">getField</a>(row, fieldName).map(_.asInstanceOf[Seq[Row]])<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Extracts a [[Map]] from a [[Row]] field of type [[Seq]] of [[Row]]s, where each inner [[Row]] is of a struct with<br/>
&nbsp;&nbsp; * field &quot;key&quot; and &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>&quot;<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param row row to extract the KV [[Row]]s from<br/>
&nbsp;&nbsp; * @param fieldName field <a href="../../fetcher/status/statusapiv1.scala.html#L48" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:48">name</a> that holds the KV [[Row]]s<br/>
&nbsp;&nbsp; * @tparam V type of <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a><br/>
&nbsp;&nbsp; * @return reconstructed map<br/>
&nbsp;&nbsp; */<br/>
<a id="L258">&#x200c;</a>&nbsp; private def <span class="linkable">getRowSeqAsMap</span>[V](row: Row, fieldName: String): Map[String, V] =<br/>
&nbsp; &nbsp; <a href="#L246" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:246">getRowSeq</a>(row, fieldName)<br/>
&nbsp; &nbsp; &nbsp; .getOrElse(Seq.empty)<br/>
&nbsp; &nbsp; &nbsp; .map(innerRow =&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; <a href="#L225" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:225">getField</a>(innerRow, &quot;key&quot;).map(_.asInstanceOf[String]) -&gt; <a href="#L225" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:225">getField</a>(innerRow, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>&quot;).map(_.asInstanceOf[V]))<br/>
&nbsp; &nbsp; &nbsp; .filter {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; case (k, v) if k.isDefined &amp;&amp; v.isDefined =&gt; true<br/>
&nbsp; &nbsp; &nbsp; &nbsp; case (k, v) =&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LOGGER.warn(s&quot;Malformed KV-pair detected in $fieldName. key: $k, <a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>: $v&quot;)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; false<br/>
&nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; &nbsp; .map { case (k, v) =&gt; k.<a href="../../fetcher/SparkRestClient.scala.html#L229" title="com/microsoft/spark/insight/fetcher/SparkRestClient.scala:229">get</a> -&gt; v.<a href="../../fetcher/SparkRestClient.scala.html#L229" title="com/microsoft/spark/insight/fetcher/SparkRestClient.scala:229">get</a> }<br/>
&nbsp; &nbsp; &nbsp; .toMap<br/>
<br/>
&nbsp; private val APP_ATTEMPT_INFO_FIELDS =<br/>
&nbsp; &nbsp; Seq(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L60" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:60">startTime</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L61" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:61">endTime</a>&quot;, &quot;lastUpdated&quot;, &quot;duration&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L62" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:62">sparkUser</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L63" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:63">completed</a>&quot;, &quot;appSparkVersion&quot;)<br/>
&nbsp; private val APP_INFO_FIELDS = Seq(<a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>(&quot;appid&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L47" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:47">id</a>&quot;), <a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L48" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:48">name</a>&quot;))<br/>
&nbsp; private val RUNTIME_INFO_FIELDS = Seq(&quot;javaVersion&quot;, &quot;javaHome&quot;, &quot;scalaVersion&quot;)<br/>
&nbsp; private val JOB_DATA_FIELDS = Seq(<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L104" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:104">jobId</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L48" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:48">name</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L106" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:106">description</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L107" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:107">submissionTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L108" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:108">completionTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L109" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:109">stageIds</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L110" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:110">jobGroup</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L111" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:111">status</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L112" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:112">numTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L113" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:113">numActiveTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L114" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:114">numCompletedTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L115" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:115">numSkippedTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L116" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:116">numFailedTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;numKilledTasks&quot;,<br/>
&nbsp; &nbsp; &quot;numCompletedIndices&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L117" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:117">numActiveStages</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L118" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:118">numCompletedStages</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L119" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:119">numSkippedStages</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L120" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:120">numFailedStages</a>&quot;)<br/>
&nbsp; private val STAGE_DATA_FIELDS = Seq(<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L111" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:111">status</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L112" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:112">numTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L113" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:113">numActiveTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L154" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:154">numCompleteTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L116" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:116">numFailedTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;numKilledTasks&quot;,<br/>
&nbsp; &nbsp; &quot;numCompletedIndices&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L107" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:107">submissionTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L160" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:160">firstTaskLaunchedTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L108" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:108">completionTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L162" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:162">failureReason</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L242" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:242">executorDeserializeCpuTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L157" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:157">executorRunTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L158" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:158">executorCpuTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L207" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:207">resultSize</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L209" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:209">resultSerializationTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L74" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:74">memoryBytesSpilled</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L75" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:75">diskBytesSpilled</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L70" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:70">inputBytes</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L165" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:165">inputRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L71" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:71">outputBytes</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L167" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:167">outputRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;shuffleRemoteBlocksFetched&quot;,<br/>
&nbsp; &nbsp; &quot;shuffleLocalBlocksFetched&quot;,<br/>
&nbsp; &nbsp; &quot;shuffleFetchBackoffCount&quot;,<br/>
&nbsp; &nbsp; &quot;shuffleRemoteBytesRead&quot;,<br/>
&nbsp; &nbsp; &quot;shuffleRemoteBytesReadToDisk&quot;,<br/>
&nbsp; &nbsp; &quot;shuffleLocalBytesRead&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L168" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:168">shuffleReadBytes</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L169" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:169">shuffleReadRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L170" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:170">shuffleWriteBytes</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L171" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:171">shuffleWriteRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L48" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:48">name</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L106" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:106">description</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L176" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:176">details</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L177" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:177">schedulingPool</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L97" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:97">peakJvmUsedMemory</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L184" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:184">peakExecutionMemory</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L185" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:185">peakStorageMemory</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L98" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:98">peakUnifiedMemory</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L205" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:205">executorDeserializeTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L208" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:208">jvmGcTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;shuffleReadFetchWaitTime&quot;,<br/>
&nbsp; &nbsp; &quot;shuffleWriteTime&quot;,<br/>
&nbsp; &nbsp; &quot;rddIds&quot;).map(<a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>(_)) ++ Seq(<br/>
&nbsp; &nbsp; <a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>(&quot;stageattemptid&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>&quot;),<br/>
&nbsp; &nbsp; <a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>(&quot;shufflereadfetchwaittime&quot;, &quot;shuffleFetchWaitTime&quot;))<br/>
&nbsp; private val ACCUMULATOR_UPDATE_FIELDS = Seq(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L47" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:47">id</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L48" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:48">name</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L304" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:304">update</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a>&quot;)<br/>
&nbsp; private val TASK_SUMMARY_FIELDS = Seq(<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L239" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:239">quantiles</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L205" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:205">executorDeserializeTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L242" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:242">executorDeserializeCpuTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L157" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:157">executorRunTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L158" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:158">executorCpuTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L207" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:207">resultSize</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L208" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:208">jvmGcTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L209" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:209">resultSerializationTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L248" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:248">gettingResultTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L249" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:249">schedulerDelay</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L184" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:184">peakExecutionMemory</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L74" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:74">memoryBytesSpilled</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L75" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:75">diskBytesSpilled</a>&quot;)<br/>
&nbsp; private val INPUT_METRICS_FIELDS = Seq(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L218" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:218">bytesRead</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L219" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:219">recordsRead</a>&quot;)<br/>
&nbsp; private val OUTPUT_METRICS_FIELDS = Seq(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L222" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:222">bytesWritten</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L223" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:223">recordsWritten</a>&quot;)<br/>
&nbsp; private val SHUFFLE_READ_METRICS_FIELDS = Seq(<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L268" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:268">readBytes</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L269" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:269">readRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L226" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:226">remoteBlocksFetched</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L227" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:227">localBlocksFetched</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L228" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:228">fetchWaitTime</a>&quot;,<br/>
&nbsp; &nbsp; &quot;fetchBackoffCount&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L229" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:229">remoteBytesRead</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L274" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:274">remoteBytesReadToDisk</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L230" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:230">totalBlocksFetched</a>&quot;)<br/>
&nbsp; private val SHUFFLE_WRITE_METRICS_FIELDS = Seq(&quot;<a href="../../fetcher/status/statusapiv1.scala.html#L278" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:278">writeBytes</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L279" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:279">writeRecords</a>&quot;, &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L235" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:235">writeTime</a>&quot;)<br/>
&nbsp; private val EXEC_METRICS_SUMMARY_FIELDS = Seq(<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L239" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:239">quantiles</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L112" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:112">numTasks</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L70" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:70">inputBytes</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L165" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:165">inputRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L71" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:71">outputBytes</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L167" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:167">outputRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L72" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:72">shuffleRead</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L169" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:169">shuffleReadRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L73" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:73">shuffleWrite</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L171" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:171">shuffleWriteRecords</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L74" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:74">memoryBytesSpilled</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L75" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:75">diskBytesSpilled</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L97" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:97">peakJvmUsedMemory</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L184" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:184">peakExecutionMemory</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L185" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:185">peakStorageMemory</a>&quot;,<br/>
&nbsp; &nbsp; &quot;<a href="../../fetcher/status/statusapiv1.scala.html#L98" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:98">peakUnifiedMemory</a>&quot;)<br/>
<br/>
&nbsp; private val typeToFieldNames: Map[Type, Seq[<a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRowConversionUtils.scala:215">FieldNamePair</a>]] = Map(<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L46" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:46">ApplicationInfo</a>] -&gt; APP_INFO_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L58" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:58">ApplicationAttemptInfo</a>] -&gt; APP_ATTEMPT_INFO_FIELDS,<br/>
&nbsp; &nbsp; typeOf[RuntimeInfo] -&gt; RUNTIME_INFO_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L103" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:103">JobData</a>] -&gt; JOB_DATA_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L148" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:148">StageData</a>] -&gt; STAGE_DATA_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L301" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:301">AccumulableInfo</a>] -&gt; ACCUMULATOR_UPDATE_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L238" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:238">TaskMetricDistributions</a>] -&gt; TASK_SUMMARY_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L259" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:259">InputMetricDistributions</a>] -&gt; INPUT_METRICS_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L263" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:263">OutputMetricDistributions</a>] -&gt; OUTPUT_METRICS_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L267" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:267">ShuffleReadMetricDistributions</a>] -&gt; SHUFFLE_READ_METRICS_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L277" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:277">ShuffleWriteMetricDistributions</a>] -&gt; SHUFFLE_WRITE_METRICS_FIELDS,<br/>
&nbsp; &nbsp; typeOf[<a href="../../fetcher/status/statusapiv1.scala.html#L282" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:282">ExecutorMetricDistributions</a>] -&gt; EXEC_METRICS_SUMMARY_FIELDS)<br/>
}<br/>
</code>

 </body>
</html>
