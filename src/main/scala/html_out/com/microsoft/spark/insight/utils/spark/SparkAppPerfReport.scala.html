<!-- generated by the src2html.pl tool from code2ebook:
  https://github.com/agentzh/code2ebook
-->

<html>
 <head>
  <title>com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala - Spark Insight</title>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <style>
body {
    text-align: left;
    text-align-last: left;
}

code {
    font-family: consolas, monospace;
    line-height: 130%;
}


  </style>
 </head>
 <body>

  <h1>com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala - Spark Insight</h1>
 <h2>Data types defined</h2>
 <ul class="toc">
<li><a href="#L26">SparkAppPerfReport</a></li>
<li><a href="#L115">SparkAppPerfReport</a></li>
<li><a href="#L127">StageIdAttemptId</a></li>
<li><a href="#L131">StageIdAttemptId</a></li>
</ul>
 <h2>Functions defined</h2>
 <ul class="toc">
<li><a href="#L145">PerfMetrics</a></li>
<li><a href="#L188">accumulatedMetrics</a></li>
<li><a href="#L142">apply</a></li>
<li><a href="#L147">combineOp</a></li>
<li><a href="#L220">diffDatesInMillis</a></li>
<li><a href="#L197">extractAppAttempt</a></li>
<li><a href="#L39">incompleteAppRun</a></li>
<li><a href="#L202">isSuccessfulJobData</a></li>
<li><a href="#L218">localDate</a></li>
<li><a href="#L227">nanosToMillis</a></li>
<li><a href="#L215">objectDebugString</a></li>
<li><a href="#L153">perStagePerfMetrics</a></li>
<li><a href="#L53">retriedStagesExist</a></li>
<li><a href="#L46">unsuccessfulJobsExist</a></li>
<li><a href="#L158">verifyValidAppInfo</a></li>
</ul>
 <h2>Source code</h2>

  <code>package com.microsoft.spark.insight.utils.spark<br/>
<br/>
import java.time.temporal.ChronoUnit<br/>
import java.time.{LocalDateTime, ZoneId}<br/>
import java.util.Date<br/>
import java.util.concurrent.TimeUnit<br/>
<br/>
import com.microsoft.spark.insight.utils.<a href="../PerfMetric.scala.html#L17" title="com/microsoft/spark/insight/utils/PerfMetric.scala:17">PerfMetric</a>._<br/>
import com.microsoft.spark.insight.utils._<br/>
import com.microsoft.spark.insight.utils.spark.<a href="RawSparkApplicationAttempt.scala.html#L14" title="com/microsoft/spark/insight/utils/spark/RawSparkApplicationAttempt.scala:14">RawSparkApplicationAttempt</a>.{AttemptId, JobId, StageId}<br/>
import com.microsoft.spark.insight.utils.spark.<a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>.FIRST_APP_ATTEMPT<br/>
import com.microsoft.spark.insight.utils.spark.<a href="#L26" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:26">SparkAppPerfReport</a>.<a href="#L127" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:127">StageIdAttemptId</a><br/>
import org.apache.commons.lang3.builder.{ReflectionToStringBuilder, ToStringStyle}<br/>
import org.apache.spark.JobExecutionStatus<br/>
import org.apache.spark.<a href="../../fetcher/status/statusapiv1.scala.html#L111" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:111">status</a>.api.v1.{<a href="../../fetcher/status/statusapiv1.scala.html#L46" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:46">ApplicationInfo</a>, <a href="../../fetcher/status/statusapiv1.scala.html#L103" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:103">JobData</a>, <a href="../../fetcher/status/statusapiv1.scala.html#L148" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:148">StageData</a>}<br/>
import org.slf4j.{Logger, LoggerFactory}<br/>
<br/>
import scala.collection.immutable.ListMap<br/>
<br/>
/**<br/>
 * A Spark application performance report - takes a [[<a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>]] and extracts/transforms specific metrics per<br/>
 * <a href="PerJobReport.scala.html#L48" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:48">job</a>, per <a href="PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a> and another summarized view of the entire application<br/>
 *<br/>
 * @param rawSparkMetrics Raw Spark metrics retrieved from a [[<a href="SparkMetricsRetriever.scala.html#L6" title="com/microsoft/spark/insight/utils/spark/SparkMetricsRetriever.scala:6">SparkMetricsRetriever</a>]]<br/>
 */<br/>
<a id="L26">&#x200c;</a>class <span class="linkable">SparkAppPerfReport</span>(val rawSparkMetrics: <a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>)<br/>
&nbsp; &nbsp; extends <a href="SparkAppPerfReportBase.scala.html#L19" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:19">SparkAppPerfReportBase</a>[JobId, <a href="#L127" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:127">StageIdAttemptId</a>, <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue]] {<br/>
&nbsp; import <a href="#L26" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:26">SparkAppPerfReport</a>._<br/>
<br/>
&nbsp; private var _incompleteAppRun: Boolean = _<br/>
&nbsp; private var _unsuccessfulJobsExist: Boolean = _<br/>
&nbsp; private var _retriedStagesExist: Boolean = _<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Return true/false whether this app run was marked as <a href="../../fetcher/status/statusapiv1.scala.html#L63" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:63">completed</a><br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @return true iff app run is incomplete<br/>
&nbsp;&nbsp; */<br/>
<a id="L39">&#x200c;</a>&nbsp; def <span class="linkable">incompleteAppRun</span>: Boolean = _incompleteAppRun<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Return true/false whether unsuccessful jobs exist in this application run<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @return true iff unsuccessful jobs were detected for this run<br/>
&nbsp;&nbsp; */<br/>
<a id="L46">&#x200c;</a>&nbsp; def <span class="linkable">unsuccessfulJobsExist</span>: Boolean = _unsuccessfulJobsExist<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Return true/false whether stages with multiple <a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a> exist in this application run<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @return true iff stages with multiple <a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a> were detected for this run<br/>
&nbsp;&nbsp; */<br/>
<a id="L53">&#x200c;</a>&nbsp; def <span class="linkable">retriedStagesExist</span>: Boolean = _retriedStagesExist<br/>
<br/>
&nbsp; override protected def <a href="SparkAppPerfReportBase.scala.html#L33" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:33">buildPerJobData</a>: () =&gt; Seq[(JobId, Seq[(<a href="#L127" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:127">StageIdAttemptId</a>, <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue])])] =<br/>
&nbsp; &nbsp; () =&gt; {<br/>
&nbsp; &nbsp; &nbsp; // Extract and validate the first app <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a><br/>
&nbsp; &nbsp; &nbsp; val appAttempt = <a href="#L197" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:197">extractAppAttempt</a>(rawSparkMetrics)<br/>
&nbsp; &nbsp; &nbsp; val stageDataMap = appAttempt.stageDataMap<br/>
<br/>
&nbsp; &nbsp; &nbsp; _incompleteAppRun = !appAttempt.appAttemptInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L63" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:63">completed</a><br/>
<br/>
&nbsp; &nbsp; &nbsp; // Check whether there were stages with more than a single <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a><br/>
&nbsp; &nbsp; &nbsp; _retriedStagesExist = stageDataMap.exists(_._2.size &gt; 1)<br/>
<br/>
&nbsp; &nbsp; &nbsp; appAttempt.jobDataMap.values<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .map(jobData =&gt; {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; _unsuccessfulJobsExist |= !<a href="#L202" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:202">isSuccessfulJobData</a>(jobData)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // Extract the stages corresponding to this <a href="../../fetcher/status/statusapiv1.scala.html#L104" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:104">jobId</a><br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; val stageDatas = stageDataMap.filterKeys(jobData.<a href="../../fetcher/status/statusapiv1.scala.html#L109" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:109">stageIds</a>.toSet).values.flatMap(_.values)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; jobData.<a href="../../fetcher/status/statusapiv1.scala.html#L104" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:104">jobId</a> -&gt; <a href="#L153" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:153">perStagePerfMetrics</a>(stageDatas)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; })<br/>
&nbsp; &nbsp; &nbsp; &nbsp; .toSeq<br/>
&nbsp; &nbsp; }<br/>
<br/>
&nbsp; // <a href="#L26" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:26">SparkAppPerfReport</a> should throw an exception if the rawMetrics are invalid<br/>
&nbsp; if (!<a href="SparkAppPerfReportBase.scala.html#L56" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:56">perJobReport</a>.<a href="PerJobReport.scala.html#L40" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:40">isValid</a>) {<br/>
&nbsp; &nbsp; throw <a href="SparkAppPerfReportBase.scala.html#L56" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:56">perJobReport</a>.<a href="PerJobReport.scala.html#L33" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:33">failure</a><br/>
&nbsp; }<br/>
<br/>
&nbsp; if (_retriedStagesExist) {<br/>
&nbsp; &nbsp; LOGGER.warn(<br/>
&nbsp; &nbsp; &nbsp; s&quot;${rawSparkMetrics.<a href="RawSparkMetrics.scala.html#L31" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:31">appId</a>} contains stages with multiple <a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>. This can severely affect &quot; +<br/>
&nbsp; &nbsp; &nbsp; &nbsp; s&quot;the metrics that were recorded, hence comparing it to other runs should be avoided.&quot;)<br/>
&nbsp; }<br/>
<br/>
&nbsp; override protected def <a href="SparkAppPerfReportBase.scala.html#L40" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:40">buildSummaryReport</a>: () =&gt; <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue] = () =&gt; {<br/>
&nbsp; &nbsp; if (<a href="SparkAppPerfReportBase.scala.html#L56" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:56">perJobReport</a>.<a href="PerJobReport.scala.html#L40" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:40">isValid</a>) {<br/>
&nbsp; &nbsp; &nbsp; // Sum-up all of the 'accumulable' metrics across all stages<br/>
&nbsp; &nbsp; &nbsp; val accumlablePerfMetrics = <a href="#L188" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:188">accumulatedMetrics</a>(<a href="SparkAppPerfReportBase.scala.html#L56" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:56">perJobReport</a>.<a href="PerJobReport.scala.html#L55" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:55">allJobs</a>.flatMap(_.<a href="PerStageReport.scala.html#L33" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:33">allStages</a>))<br/>
<br/>
&nbsp; &nbsp; &nbsp; // Produce the summary-specific metrics<br/>
&nbsp; &nbsp; &nbsp; val summaryPerfMetrics = {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; val rawSparkApplicationAttempt = <a href="#L197" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:197">extractAppAttempt</a>(rawSparkMetrics)<br/>
&nbsp; &nbsp; &nbsp; &nbsp; summaryPerfMetricsMethods.map(_.<a href="../../cli/AppReportSets.scala.html#L43" title="com/microsoft/spark/insight/cli/AppReportSets.scala:43">apply</a>(rawSparkApplicationAttempt)).toMap<br/>
&nbsp; &nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; &nbsp; accumlablePerfMetrics ++ summaryPerfMetrics<br/>
&nbsp; &nbsp; } else {<br/>
&nbsp; &nbsp; &nbsp; Map.empty<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
&nbsp; override protected def <a href="SparkAppPerfReportBase.scala.html#L48" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:48">buildJobLevelReport</a>: () =&gt; ListMap[JobId, <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue]] = () =&gt; {<br/>
&nbsp; &nbsp; var jobLevelData = ListMap[JobId, <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue]]()<br/>
&nbsp; &nbsp; if (<a href="SparkAppPerfReportBase.scala.html#L56" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:56">perJobReport</a>.<a href="PerJobReport.scala.html#L40" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:40">isValid</a>) {<br/>
&nbsp; &nbsp; &nbsp; for (jobKey &lt;- <a href="SparkAppPerfReportBase.scala.html#L56" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:56">perJobReport</a>.<a href="PerJobReport.scala.html#L62" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:62">jobKeys</a>) {<br/>
&nbsp; &nbsp; &nbsp; &nbsp; jobLevelData += (jobKey -&gt; <a href="#L188" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:188">accumulatedMetrics</a>(<a href="SparkAppPerfReportBase.scala.html#L56" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReportBase.scala:56">perJobReport</a>.<a href="PerJobReport.scala.html#L48" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:48">job</a>(jobKey).<a href="PerStageReport.scala.html#L33" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:33">allStages</a>))<br/>
&nbsp; &nbsp; &nbsp; }<br/>
&nbsp; &nbsp; }<br/>
&nbsp; &nbsp; jobLevelData<br/>
&nbsp; }<br/>
}<br/>
<br/>
<a id="L115">&#x200c;</a>object <span class="linkable">SparkAppPerfReport</span> {<br/>
&nbsp; val LOGGER: Logger = LoggerFactory.getLogger(classOf[<a href="#L26" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:26">SparkAppPerfReport</a>])<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * A pair of a StageId and a <a href="PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a> AttemptId. Used as a StageKey to be able to distinguish different <a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>. This<br/>
&nbsp;&nbsp; * type of report is the only one to utilize this type as it only represents a single application. Other reports<br/>
&nbsp;&nbsp; * perform matching between several [<a href="#L26" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:26">SparkAppPerfReport</a>]s, and matching is designed to fail in the <a href="PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a>-level for<br/>
&nbsp;&nbsp; * runs with multiple <a href="PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a> <a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>, as those may severely skew per-<a href="PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a> metrics<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param <a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a> <a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a><br/>
&nbsp;&nbsp; * @param <a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a> <a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a><br/>
&nbsp;&nbsp; */<br/>
<a id="L127">&#x200c;</a>&nbsp; case class <span class="linkable">StageIdAttemptId</span>(<a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a>: StageId, <a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>: AttemptId) {<br/>
&nbsp; &nbsp; override def toString: String = s&quot;StageId: $<a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a>, AttemptId: $<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>&quot;<br/>
&nbsp; }<br/>
<br/>
<a id="L131">&#x200c;</a>&nbsp; object <span class="linkable">StageIdAttemptId</span> {<br/>
<br/>
&nbsp; &nbsp; /** The first <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a> ID used in Spark apps */<br/>
&nbsp; &nbsp; val FIRST_STAGE_ATTEMPT_ID = 0<br/>
<br/>
&nbsp; &nbsp; /**<br/>
&nbsp; &nbsp;&nbsp; * A convenience method for creating a [[<a href="#L127" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:127">StageIdAttemptId</a>]] for a <a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a> with the [[FIRST_STAGE_ATTEMPT_ID]]<br/>
&nbsp; &nbsp;&nbsp; *<br/>
&nbsp; &nbsp;&nbsp; * @param <a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a> <a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a><br/>
&nbsp; &nbsp;&nbsp; * @return stageIdAttemptId with the provided <a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a> and <a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a> set to [[FIRST_STAGE_ATTEMPT_ID]]<br/>
&nbsp; &nbsp;&nbsp; */<br/>
<a id="L142">&#x200c;</a>&nbsp; &nbsp; def <span class="linkable">apply</span>(<a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a>: StageId): <a href="#L127" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:127">StageIdAttemptId</a> = <a href="#L127" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:127">StageIdAttemptId</a>(<a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a>, FIRST_STAGE_ATTEMPT_ID)<br/>
&nbsp; }<br/>
<br/>
<a id="L145">&#x200c;</a>&nbsp; private def <span class="linkable">PerfMetrics</span>(stageData: <a href="../../fetcher/status/statusapiv1.scala.html#L148" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:148">StageData</a>): <span class="linkable">PerfMetrics</span>[PerfValue] =<br/>
&nbsp; &nbsp; perStagePerfMetricsMethods.map(_.<a href="../../cli/AppReportSets.scala.html#L43" title="com/microsoft/spark/insight/cli/AppReportSets.scala:43">apply</a>(stageData)).toMap<br/>
<a id="L147">&#x200c;</a>&nbsp; private def <span class="linkable">combineOp</span>(<br/>
&nbsp; &nbsp; &nbsp; perfMetrics1: <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue],<br/>
&nbsp; &nbsp; &nbsp; perfMetrics2: <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue]): <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue] = {<br/>
&nbsp; &nbsp; perfMetrics1 ++ perfMetrics2.map { case (k, v) =&gt; k -&gt; (v + perfMetrics1.getOrElse(k, 0L)) }<br/>
&nbsp; }<br/>
<br/>
<a id="L153">&#x200c;</a>&nbsp; private def <span class="linkable">perStagePerfMetrics</span>(stageDatas: Iterable[<a href="../../fetcher/status/statusapiv1.scala.html#L148" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:148">StageData</a>]) =<br/>
&nbsp; &nbsp; stageDatas<br/>
&nbsp; &nbsp; &nbsp; .map(stageData =&gt; <a href="#L127" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:127">StageIdAttemptId</a>(stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L150" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:150">stageId</a>, stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>) -&gt; <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>(stageData))<br/>
&nbsp; &nbsp; &nbsp; .toSeq<br/>
<br/>
<a id="L158">&#x200c;</a>&nbsp; private def <span class="linkable">verifyValidAppInfo</span>(appInfo: <a href="../../fetcher/status/statusapiv1.scala.html#L46" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:46">ApplicationInfo</a>) {<br/>
&nbsp; &nbsp; if (appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>.size != 1) {<br/>
&nbsp; &nbsp; &nbsp; throw new IllegalArgumentException(s&quot;Invalid Spark app detected: (${appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L47" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:47">id</a>}) - contains &quot; +<br/>
&nbsp; &nbsp; &nbsp; &nbsp; s&quot;${appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>.size} <a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>. Report creation for applications with more than a single <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a> is not&quot; +<br/>
&nbsp; &nbsp; &nbsp; &nbsp; s&quot; supported&quot;)<br/>
&nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; val firstAttempt = appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L49" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:49">attempts</a>.head<br/>
&nbsp; &nbsp; firstAttempt.<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a> match {<br/>
&nbsp; &nbsp; &nbsp; case Some(<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>) if !<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>.equals(FIRST_APP_ATTEMPT) =&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; throw new IllegalArgumentException(<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; s&quot;Invalid Spark app detected: (${appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L47" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:47">id</a>}) - contains an unexpected application <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a> <a href="../../fetcher/status/statusapiv1.scala.html#L47" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:47">id</a>. Actual: &quot; +<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; s&quot;$<a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>, expected: $FIRST_APP_ATTEMPT&quot;)<br/>
&nbsp; &nbsp; &nbsp; case None =&gt;<br/>
&nbsp; &nbsp; &nbsp; &nbsp; throw new IllegalArgumentException(<br/>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; s&quot;Invalid Spark app detected: (${appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L47" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:47">id</a>}) - contains an undefined <a href="../../fetcher/status/statusapiv1.scala.html#L59" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:59">attemptId</a>&quot;)<br/>
&nbsp; &nbsp; &nbsp; case _ =&gt;<br/>
&nbsp; &nbsp; }<br/>
<br/>
&nbsp; &nbsp; if (!firstAttempt.<a href="../../fetcher/status/statusapiv1.scala.html#L63" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:63">completed</a>) {<br/>
&nbsp; &nbsp; &nbsp; LOGGER.warn(s&quot;Incomplete Spark app detected: (${appInfo.<a href="../../fetcher/status/statusapiv1.scala.html#L47" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:47">id</a>}) - application is still running&quot;)<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Accumulate all the accumulable metrics into a single PerfMetricsType<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param allStagesMetrics corresponding Iterable Seq of PerfMetricsType<br/>
&nbsp;&nbsp; * @return accumulated PerfMetricsType<br/>
&nbsp;&nbsp; */<br/>
<a id="L188">&#x200c;</a>&nbsp; def <span class="linkable">accumulatedMetrics</span>(allStagesMetrics: Iterable[<a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue]]): <a href="#L145" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:145">PerfMetrics</a>[PerfValue] =<br/>
&nbsp; &nbsp; allStagesMetrics.map(_.filter(_._1.accumulable)).reduce(<a href="#L147" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:147">combineOp</a>)<br/>
<br/>
&nbsp; /**<br/>
&nbsp;&nbsp; * Extract the first Application Attempt raw metrics from a spark application.<br/>
&nbsp;&nbsp; *<br/>
&nbsp;&nbsp; * @param rawSparkMetrics raw data collected from SHS for a specific Spark application<br/>
&nbsp;&nbsp; * @return [[<a href="RawSparkApplicationAttempt.scala.html#L14" title="com/microsoft/spark/insight/utils/spark/RawSparkApplicationAttempt.scala:14">RawSparkApplicationAttempt</a>]] for an application <a href="../../fetcher/status/statusapiv1.scala.html#L193" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:193">attempt</a><br/>
&nbsp;&nbsp; */<br/>
<a id="L197">&#x200c;</a>&nbsp; def <span class="linkable">extractAppAttempt</span>(rawSparkMetrics: <a href="RawSparkMetrics.scala.html#L13" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:13">RawSparkMetrics</a>): <a href="RawSparkApplicationAttempt.scala.html#L14" title="com/microsoft/spark/insight/utils/spark/RawSparkApplicationAttempt.scala:14">RawSparkApplicationAttempt</a> = {<br/>
&nbsp; &nbsp; <a href="#L158" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:158">verifyValidAppInfo</a>(rawSparkMetrics.appInfo)<br/>
&nbsp; &nbsp; rawSparkMetrics.<a href="RawSparkMetrics.scala.html#L21" title="com/microsoft/spark/insight/utils/spark/RawSparkMetrics.scala:21">firstAppAttempt</a><br/>
&nbsp; }<br/>
<br/>
<a id="L202">&#x200c;</a>&nbsp; private def <span class="linkable">isSuccessfulJobData</span>(jobData: <a href="../../fetcher/status/statusapiv1.scala.html#L103" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:103">JobData</a>): Boolean = {<br/>
&nbsp; &nbsp; if (!jobData.<a href="../../fetcher/status/statusapiv1.scala.html#L111" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:111">status</a>.equals(JobExecutionStatus.SUCCEEDED)) {<br/>
&nbsp; &nbsp; &nbsp; LOGGER.warn(s&quot;Unsuccessful <a href="PerJobReport.scala.html#L48" title="com/microsoft/spark/insight/utils/spark/PerJobReport.scala:48">job</a> detected: \<a href="../AggregatePerfValue.scala.html#L28" title="com/microsoft/spark/insight/utils/AggregatePerfValue.scala:28">n</a>${<a href="#L215" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:215">objectDebugString</a>(jobData)}&quot;)<br/>
&nbsp; &nbsp; &nbsp; false<br/>
&nbsp; &nbsp; } else {<br/>
&nbsp; &nbsp; &nbsp; true<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
&nbsp; /*<br/>
&nbsp;&nbsp; * Construct debug strings from all of the members of an object (used for printing classes that doesn't have an<br/>
&nbsp;&nbsp; *&nbsp; overloaded toString method)<br/>
&nbsp;&nbsp; */<br/>
<a id="L215">&#x200c;</a>&nbsp; private def <span class="linkable">objectDebugString</span>(obj: Any): String =<br/>
&nbsp; &nbsp; ReflectionToStringBuilder.toString(obj, ToStringStyle.MULTI_LINE_STYLE)<br/>
<br/>
<a id="L218">&#x200c;</a>&nbsp; private def <span class="linkable">localDate</span>(date: Date): LocalDateTime = date.toInstant.atZone(ZoneId.systemDefault).toLocalDateTime<br/>
<br/>
<a id="L220">&#x200c;</a>&nbsp; private def <span class="linkable">diffDatesInMillis</span>(earlierDate: Option[Date], laterDate: Option[Date]): Long = {<br/>
&nbsp; &nbsp; (earlierDate, laterDate) match {<br/>
&nbsp; &nbsp; &nbsp; case (Some(date1), Some(date2)) =&gt; ChronoUnit.MILLIS.between(<a href="#L218" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:218">localDate</a>(date1), <a href="#L218" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:218">localDate</a>(date2))<br/>
&nbsp; &nbsp; &nbsp; case _ =&gt; 0L<br/>
&nbsp; &nbsp; }<br/>
&nbsp; }<br/>
<br/>
<a id="L227">&#x200c;</a>&nbsp; private def <span class="linkable">nanosToMillis</span>(data: Long): Long = TimeUnit.NANOSECONDS.toMillis(data)<br/>
<br/>
&nbsp; /*<br/>
&nbsp;&nbsp; * A collection of methods to extract and/or transform specific metrics from stageDatas<br/>
&nbsp;&nbsp; */<br/>
&nbsp; private val perStagePerfMetricsMethods: Seq[<a href="../../fetcher/status/statusapiv1.scala.html#L148" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:148">StageData</a> =&gt; (<a href="../PerfMetric.scala.html#L17" title="com/microsoft/spark/insight/utils/PerfMetric.scala:17">PerfMetric</a>, PerfValue)] = List(<br/>
&nbsp; &nbsp; stageData =&gt; TOTAL_RUNNING_TIME -&gt; <a href="#L220" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:220">diffDatesInMillis</a>(stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L107" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:107">submissionTime</a>, stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L108" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:108">completionTime</a>),<br/>
&nbsp; &nbsp; stageData =&gt;<br/>
&nbsp; &nbsp; &nbsp; SUBMISSION_TO_FIRST_LAUNCH_DELAY -&gt; <a href="#L220" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:220">diffDatesInMillis</a>(stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L107" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:107">submissionTime</a>, stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L160" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:160">firstTaskLaunchedTime</a>),<br/>
&nbsp; &nbsp; stageData =&gt;<br/>
&nbsp; &nbsp; &nbsp; FIRST_LAUNCH_TO_COMPLETED -&gt; <a href="#L220" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:220">diffDatesInMillis</a>(stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L160" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:160">firstTaskLaunchedTime</a>, stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L108" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:108">completionTime</a>),<br/>
&nbsp; &nbsp; stageData =&gt;<br/>
&nbsp; &nbsp; &nbsp; EXECUTOR_RUNTIME_LESS_SHUFFLE -&gt; (stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L157" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:157">executorRunTime</a> - stageData.shuffleFetchWaitTime - <a href="#L227" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:227">nanosToMillis</a>(<br/>
&nbsp; &nbsp; &nbsp; &nbsp; stageData.shuffleWriteTime)),<br/>
&nbsp; &nbsp; stageData =&gt; EXECUTOR_RUNTIME -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L157" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:157">executorRunTime</a>,<br/>
&nbsp; &nbsp; stageData =&gt; EXECUTOR_CPU_TIME -&gt; <a href="#L227" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:227">nanosToMillis</a>(stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L158" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:158">executorCpuTime</a>),<br/>
&nbsp; &nbsp; stageData =&gt; JVM_GC_TIME -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L208" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:208">jvmGcTime</a>,<br/>
&nbsp; &nbsp; stageData =&gt; SHUFFLE_READ_FETCH_WAIT_TIME -&gt; stageData.shuffleFetchWaitTime,<br/>
&nbsp; &nbsp; stageData =&gt; SHUFFLE_WRITE_TIME -&gt; <a href="#L227" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:227">nanosToMillis</a>(stageData.shuffleWriteTime),<br/>
&nbsp; &nbsp; stageData =&gt; INPUT_SIZE -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L70" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:70">inputBytes</a>,<br/>
&nbsp; &nbsp; stageData =&gt; INPUT_RECORDS -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L165" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:165">inputRecords</a>,<br/>
&nbsp; &nbsp; stageData =&gt; OUTPUT_SIZE -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L71" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:71">outputBytes</a>,<br/>
&nbsp; &nbsp; stageData =&gt; OUTPUT_RECORDS -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L167" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:167">outputRecords</a>,<br/>
&nbsp; &nbsp; stageData =&gt; SHUFFLE_READ_SIZE -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L168" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:168">shuffleReadBytes</a>,<br/>
&nbsp; &nbsp; stageData =&gt; SHUFFLE_READ_RECORDS -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L169" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:169">shuffleReadRecords</a>,<br/>
&nbsp; &nbsp; stageData =&gt; SHUFFLE_WRITE_SIZE -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L170" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:170">shuffleWriteBytes</a>,<br/>
&nbsp; &nbsp; stageData =&gt; SHUFFLE_WRITE_RECORDS -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L171" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:171">shuffleWriteRecords</a>,<br/>
&nbsp; &nbsp; stageData =&gt; MEM_SPILLS -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L74" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:74">memoryBytesSpilled</a>,<br/>
&nbsp; &nbsp; stageData =&gt; DISK_SPILLS -&gt; stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L75" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:75">diskBytesSpilled</a>,<br/>
&nbsp; &nbsp; stageData =&gt;<br/>
&nbsp; &nbsp; &nbsp; NET_IO_TIME -&gt; (stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L157" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:157">executorRunTime</a> - stageData.shuffleFetchWaitTime - <a href="#L227" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:227">nanosToMillis</a>(<br/>
&nbsp; &nbsp; &nbsp; &nbsp; stageData.shuffleWriteTime) - <a href="#L227" title="com/microsoft/spark/insight/utils/spark/SparkAppPerfReport.scala:227">nanosToMillis</a>(stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L158" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:158">executorCpuTime</a>) - stageData.<a href="../../fetcher/status/statusapiv1.scala.html#L208" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:208">jvmGcTime</a>))<br/>
<br/>
&nbsp; private[spark] val summaryPerfMetricsMethods: Seq[<a href="RawSparkApplicationAttempt.scala.html#L14" title="com/microsoft/spark/insight/utils/spark/RawSparkApplicationAttempt.scala:14">RawSparkApplicationAttempt</a> =&gt; (<a href="../PerfMetric.scala.html#L17" title="com/microsoft/spark/insight/utils/PerfMetric.scala:17">PerfMetric</a>, PerfValue)] = List(<br/>
&nbsp; &nbsp; rawSparkApplicationAttempt =&gt; TOTAL_RUNNING_TIME -&gt; rawSparkApplicationAttempt.appAttemptInfo.duration)<br/>
}<br/>
</code>

 </body>
</html>
