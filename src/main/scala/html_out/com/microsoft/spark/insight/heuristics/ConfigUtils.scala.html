<!-- generated by the src2html.pl tool from code2ebook:
  https://github.com/agentzh/code2ebook
-->

<html>
 <head>
  <title>com/microsoft/spark/insight/heuristics/ConfigUtils.scala - Spark Insight</title>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <style>
body {
    text-align: left;
    text-align-last: left;
}

code {
    font-family: consolas, monospace;
    line-height: 130%;
}


  </style>
 </head>
 <body>

  <h1>com/microsoft/spark/insight/heuristics/ConfigUtils.scala - Spark Insight</h1>
 <h2>Data types defined</h2>
 <ul class="toc">
<li><a href="#L20">ConfigUtils</a></li>
</ul>
 <h2>Source code</h2>

  <code>/*<br/>
 * Licensed to the Apache Software Foundation (ASF) under one or more<br/>
 * contributor license agreements.&nbsp; See the NOTICE file distributed with<br/>
 * this work for additional information regarding copyright ownership.<br/>
 * The ASF licenses this file to You under the Apache License, Version 2.0<br/>
 * (the &quot;License&quot;); you may not use this file except in compliance with<br/>
 * the License.&nbsp; You may obtain a copy of the License at<br/>
 *<br/>
 *&nbsp; &nbsp; http://www.apache.org/licenses/LICENSE-2.0<br/>
 *<br/>
 * Unless required by applicable law or agreed to in writing, software<br/>
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,<br/>
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br/>
 * See the License for the specific language governing permissions and<br/>
 * limitations under the License.<br/>
 */<br/>
<br/>
package com.microsoft.spark.insight.heuristics<br/>
<br/>
<a id="L20">&#x200c;</a>object <span class="linkable">ConfigUtils</span> {<br/>
&nbsp; val JVM_USED_MEMORY = &quot;jvmUsedMemory&quot;<br/>
<br/>
&nbsp; // Spark configuration parameters<br/>
&nbsp; val SPARK_EXECUTOR_MEMORY = &quot;spark.executor.memory&quot;<br/>
&nbsp; val SPARK_DRIVER_MEMORY = &quot;spark.driver.memory&quot;<br/>
&nbsp; val SPARK_YARN_EXECUTOR_MEMORY_OVERHEAD = &quot;spark.yarn.executor.memoryOverhead&quot;<br/>
&nbsp; val SPARK_DRIVER_MEMORY_OVERHEAD = &quot;spark.yarn.driver.memoryOverhead&quot;<br/>
&nbsp; val SPARK_EXECUTOR_CORES = &quot;spark.executor.cores&quot;<br/>
&nbsp; val SPARK_DRIVER_CORES = &quot;spark.driver.cores&quot;<br/>
&nbsp; val SPARK_EXECUTOR_INSTANCES = &quot;spark.executor.instances&quot;<br/>
&nbsp; val SPARK_SQL_SHUFFLE_PARTITIONS = &quot;spark.sql.shuffle.<a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a>&quot;<br/>
&nbsp; val SPARK_MEMORY_FRACTION = &quot;spark.memory.fraction&quot;<br/>
&nbsp; val SPARK_DRIVER_MEMORY_KEY = &quot;spark.driver.memory&quot;<br/>
&nbsp; val SPARK_EXECUTOR_MEMORY_KEY = &quot;spark.executor.memory&quot;<br/>
&nbsp; val SPARK_EXECUTOR_INSTANCES_KEY = &quot;spark.executor.instances&quot;<br/>
&nbsp; val SPARK_EXECUTOR_CORES_KEY = &quot;spark.executor.cores&quot;<br/>
&nbsp; val SPARK_SERIALIZER_KEY = &quot;spark.serializer&quot;<br/>
&nbsp; val SPARK_APPLICATION_DURATION = &quot;spark.application.duration&quot;<br/>
&nbsp; val SPARK_SHUFFLE_SERVICE_ENABLED = &quot;spark.shuffle.service.enabled&quot;<br/>
&nbsp; val SPARK_DYNAMIC_ALLOCATION_ENABLED = &quot;spark.dynamicAllocation.enabled&quot;<br/>
&nbsp; val SPARK_DRIVER_CORES_KEY = &quot;spark.driver.cores&quot;<br/>
&nbsp; val SPARK_DYNAMIC_ALLOCATION_MIN_EXECUTORS = &quot;spark.dynamicAllocation.minExecutors&quot;<br/>
&nbsp; val SPARK_DYNAMIC_ALLOCATION_MAX_EXECUTORS = &quot;spark.dynamicAllocation.maxExecutors&quot;<br/>
&nbsp; val SPARK_EXECUTOR_MEMORY_OVERHEAD = &quot;spark.executor.memoryOverhead&quot;<br/>
&nbsp; val THRESHOLD_MIN_EXECUTORS: Int = 1<br/>
&nbsp; val THRESHOLD_MAX_EXECUTORS: Int = 900<br/>
<br/>
&nbsp; // Spark default configuration values<br/>
&nbsp; val SPARK_EXECUTOR_MEMORY_DEFAULT = &quot;1g&quot;<br/>
&nbsp; val SPARK_DRIVER_MEMORY_DEFAULT = &quot;1g&quot;<br/>
&nbsp; val SPARK_EXECUTOR_CORES_DEFAULT = 1<br/>
&nbsp; val SPARK_DRIVER_CORES_DEFAULT = 1<br/>
&nbsp; val SPARK_SQL_SHUFFLE_PARTITIONS_DEFAULT = 200<br/>
&nbsp; val SPARK_MEMORY_FRACTION_DEFAULT = 0.6<br/>
<br/>
&nbsp; // if the overhead memory is not explicitly specified by the user, the default amount is<br/>
&nbsp; // <a href="../utils/AggregatePerfValue.scala.html#L26" title="com/microsoft/spark/insight/utils/AggregatePerfValue.scala:26">max</a>(0.1 * spark.executor.memory, 384MB)<br/>
&nbsp; val SPARK_MEMORY_OVERHEAD_PCT_DEFAULT = 0.1<br/>
<br/>
&nbsp; // the minimum amount of overhead memory<br/>
&nbsp; val SPARK_MEMORY_OVERHEAD_MIN_DEFAULT = 384L &lt;&lt; 20 // 384MB<br/>
<br/>
&nbsp; // the amount of Spark reserved memory (300MB)<br/>
&nbsp; val SPARK_RESERVED_MEMORY = 300L &lt;&lt; 20<br/>
<br/>
&nbsp; // number of milliseconds in a minute<br/>
&nbsp; val MILLIS_PER_MIN = 1000D * 60.0D<br/>
<br/>
&nbsp; // the <a href="../fetcher/status/statusapiv1.scala.html#L192" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:192">index</a> for the median <a href="../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> for executor and task metrics distributions<br/>
&nbsp; val DISTRIBUTION_MEDIAN_IDX = 2<br/>
<br/>
&nbsp; // the <a href="../fetcher/status/statusapiv1.scala.html#L192" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:192">index</a> for the <a href="../utils/AggregatePerfValue.scala.html#L26" title="com/microsoft/spark/insight/utils/AggregatePerfValue.scala:26">max</a> <a href="../fetcher/status/statusapiv1.scala.html#L305" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:305">value</a> for executor and task metrics distributions<br/>
&nbsp; val DISTRIBUTION_MAX_IDX = 4<br/>
<br/>
&nbsp; // keys for finding Dr. Elephant configuration parameter values<br/>
&nbsp; val SPARK_STAGE_EXECUTION_MEMORY_SPILL_THRESHOLD_KEY = &quot;spark_stage_execution_memory_spill_threshold&quot;<br/>
&nbsp; val SPARK_STAGE_TASK_SKEW_THRESHOLD_KEY = &quot;spark_stage_task_skew_threshold&quot;<br/>
&nbsp; val SPARK_STAGE_TASK_DURATION_THRESHOLD_KEY = &quot;spark_stage_task_duration_threshold&quot;<br/>
&nbsp; val SPARK_STAGE_MAX_DATA_PROCESSED_THRESHOLD_KEY = &quot;spark_stage_task_duration_threshold&quot;<br/>
&nbsp; val TASK_FAILURE_RATE_SEVERITY_THRESHOLDS_KEY = &quot;stage_task_failure_rate_severity_threshold&quot;<br/>
&nbsp; val MAX_DATA_PROCESSED_THRESHOLD_KEY = &quot;execution_memory_spill_max_data_threshold&quot;<br/>
&nbsp; val LONG_TASK_TO_STAGE_DURATION_RATIO_KEY = &quot;task_skew_task_to_stage_duration_ratio&quot;<br/>
&nbsp; val TASK_SKEW_TASK_DURATION_MIN_THRESHOLD_KEY = &quot;task_skew_task_duration_threshold&quot;<br/>
&nbsp; val MAX_RECOMMENDED_PARTITIONS_KEY = &quot;max_recommended_partitions&quot;<br/>
<br/>
&nbsp; // keys for finding specific recommendations<br/>
&nbsp; val EXECUTION_MEMORY_SPILL_LARGE_DATA_RECOMMENDATION_KEY = &quot;execution_memory_spill_large_data_recommendation&quot;<br/>
&nbsp; val TASK_SKEW_INPUT_DATA_RECOMMENDATION_KEY = &quot;task_skew_input_data_recommendation&quot;<br/>
&nbsp; val TASK_SKEW_GENERIC_RECOMMENDATION_KEY = &quot;task_skew_generic_recommendation&quot;<br/>
&nbsp; val LONG_TASKS_LARGE_DATA_RECOMMENDATION_KEY = &quot;long_tasks_large_data_recommendation&quot;<br/>
&nbsp; val SLOW_TASKS_RECOMMENDATION_KEY = &quot;slow_tasks_recommendation&quot;<br/>
&nbsp; val LONG_TASKS_FEW_PARTITIONS_RECOMMENDATION_KEY = &quot;long tasks_few_partitions&quot;<br/>
&nbsp; val LONG_TASKS_FEW_INPUT_PARTITIONS_RECOMMENDATION_KEY = &quot;long tasks_few_input_partitions&quot;<br/>
<br/>
&nbsp; // default recommendations<br/>
&nbsp; val DEFAULT_EXECUTION_MEMORY_SPILL_LARGE_DATA_RECOMMENDATION = &quot;a large amount of data is being processesd. &quot; +<br/>
&nbsp; &nbsp; &quot;Examine the application to see if this can be reduced&quot;<br/>
&nbsp; val DEFAULT_TASK_SKEW_INPUT_DATA_RECOMMENDATION = &quot;please try to modify the application to make the input <a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a> more even&quot;<br/>
&nbsp; val DEFAULT_TASK_SKEW_GENERIC_RECOMMENDATION = &quot;please try to modify the application to make the <a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a> more even&quot;<br/>
&nbsp; val DEFAULT_LONG_TASKS_LARGE_DATA_RECOMMENDATION = &quot;please try to reduce the amount of data being processed&quot;<br/>
&nbsp; val DEFAULT_SLOW_TASKS_RECOMMENDATION = &quot;please optimize the code to improve performance&quot;<br/>
&nbsp; val DEFAULT_LONG_TASKS_FEW_PARTITIONS_RECOMMENDATION = &quot;please increase the number of <a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a>&quot;<br/>
&nbsp; val DEFAULT_LONG_TASKS_FEW_INPUT_PARTITIONS_RECOMMENDATION = &quot;please increase the number of <a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a> for reading data&quot;<br/>
<br/>
&nbsp; // Severity thresholds for task duration in minutes, when checking to see if the median task<br/>
&nbsp; // run time is too long for a <a href="../utils/spark/PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a>.<br/>
&nbsp; val DEFAULT_TASK_DURATION_THRESHOLDS =<br/>
&nbsp; <a href="SeverityThresholds.scala.html#L22" title="com/microsoft/spark/insight/heuristics/SeverityThresholds.scala:22">SeverityThresholds</a>(low = 2.5D * MILLIS_PER_MIN, moderate = 5.0D * MILLIS_PER_MIN,<br/>
&nbsp; &nbsp; severe = 10.0D * MILLIS_PER_MIN, critical = 15.0D * MILLIS_PER_MIN, ascending = true)<br/>
<br/>
&nbsp; // Severity thresholds for checking task skew, ratio of maximum to median task run times.<br/>
&nbsp; val DEFAULT_TASK_SKEW_THRESHOLDS =<br/>
&nbsp; &nbsp; <a href="SeverityThresholds.scala.html#L22" title="com/microsoft/spark/insight/heuristics/SeverityThresholds.scala:22">SeverityThresholds</a>(low = 2, moderate = 4, severe = 8, critical = 16, ascending = true)<br/>
<br/>
&nbsp; // Severity thresholds for checking execution memory spill, ratio of execution spill compared<br/>
&nbsp; // to the maximum amount of data (input, output, shuffle read, or shuffle write) processed.<br/>
&nbsp; val DEFAULT_EXECUTION_MEMORY_SPILL_THRESHOLDS =<br/>
&nbsp; <a href="SeverityThresholds.scala.html#L22" title="com/microsoft/spark/insight/heuristics/SeverityThresholds.scala:22">SeverityThresholds</a>(low = 0.01D, moderate = 0.1D, severe = 0.25D, critical = 0.5D, ascending = true)<br/>
<br/>
&nbsp; // The ascending severity thresholds for the ratio of JVM GC time and task run time,<br/>
&nbsp; // checking if too much time is being spent in GC.<br/>
&nbsp; val DEFAULT_GC_SEVERITY_A_THRESHOLDS =<br/>
&nbsp; <a href="SeverityThresholds.scala.html#L22" title="com/microsoft/spark/insight/heuristics/SeverityThresholds.scala:22">SeverityThresholds</a>(low = 0.08D, moderate = 0.09D, severe = 0.1D, critical = 0.15D, ascending = true)<br/>
<br/>
&nbsp; /** The default severity thresholds for the rate of a <a href="../utils/spark/PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a>'s <a href="../fetcher/status/statusapiv1.scala.html#L180" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:180">tasks</a> failing. */<br/>
&nbsp; val DEFAULT_TASK_FAILURE_RATE_SEVERITY_THRESHOLDS =<br/>
&nbsp; &nbsp; <a href="SeverityThresholds.scala.html#L22" title="com/microsoft/spark/insight/heuristics/SeverityThresholds.scala:22">SeverityThresholds</a>(low = 0.05D, moderate = 0.1D, severe = 0.15D, critical = 0.2D, ascending = true)<br/>
<br/>
<br/>
&nbsp; // The default threshold (3TB) for checking for maximum amount of data processed, for which to<br/>
&nbsp; // alert for execution memory spill. Tasks processing more data would be expected to have some<br/>
&nbsp; // amount of spill, due to the large amount of data processed.<br/>
&nbsp; // Estimating the size based on some reasonable values for configuration parameters (and how<br/>
&nbsp; // much data could be kept in unified memory given these values):<br/>
&nbsp; //&nbsp;&nbsp; spark.executor.memory / spark.executor.cores * spark.memory.fraction *<br/>
&nbsp; //&nbsp; &nbsp;&nbsp; (1 - spark.memory.storageFraction) * spark.sql.shuffle.<a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a><br/>
&nbsp; //&nbsp;&nbsp; = 5GB / 2 * 0.6 * (1 - 0.5) * 4000<br/>
&nbsp; val DEFAULT_MAX_DATA_PROCESSED_THRESHOLD = &quot;3TB&quot;<br/>
<br/>
&nbsp; // The default threshold for the ratio of the time for longest running task for a <a href="../utils/spark/PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a> to the<br/>
&nbsp; // <a href="../utils/spark/PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a> duration. With Spark, some amount of task skew may be OK, since exectuors can process<br/>
&nbsp; // multiple <a href="../fetcher/status/statusapiv1.scala.html#L180" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:180">tasks</a>, so one executor could process multiple shorter <a href="../fetcher/status/statusapiv1.scala.html#L180" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:180">tasks</a>, while another executor<br/>
&nbsp; // processes a longer task. However, if the length of the long task is a large fraction of the<br/>
&nbsp; // <a href="../utils/spark/PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a> duration, then it is likely contributing to the overall <a href="../utils/spark/PerStageReport.scala.html#L26" title="com/microsoft/spark/insight/utils/spark/PerStageReport.scala:26">stage</a> duration.<br/>
&nbsp; val DEFAULT_LONG_TASK_TO_STAGE_DURATION_RATIO = &quot;0.75&quot;<br/>
<br/>
&nbsp; // Some task skew is also tolerable if the <a href="../fetcher/status/statusapiv1.scala.html#L180" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:180">tasks</a> are short (2.5 minutes or less).<br/>
&nbsp; val DEFAULT_TASK_SKEW_TASK_DURATION_MIN_THRESHOLD = &quot;150000&quot;<br/>
<br/>
&nbsp; // The target task duration (2.5 minutes). This is the same as the idle executor timeout.<br/>
&nbsp; val DEFAULT_TARGET_TASK_DURATION = &quot;150000&quot;<br/>
<br/>
&nbsp; // The default maximum number of <a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a> that would be recommended. More <a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a> means<br/>
&nbsp; // less data per partition, so shorter <a href="../fetcher/status/statusapiv1.scala.html#L180" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:180">tasks</a> and less memory needed per task. However more<br/>
&nbsp; // <a href="../fetcher/status/statusapiv1.scala.html#L133" title="com/microsoft/spark/insight/fetcher/status/statusapiv1.scala:133">partitions</a> also inceases the amount of overhead for shuffle.<br/>
&nbsp; val DEFAULT_MAX_RECOMMENDED_PARTITIONS = &quot;4000&quot;<br/>
}<br/>
</code>

 </body>
</html>
